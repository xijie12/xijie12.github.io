{"meta":{"title":"don't be evil","subtitle":"sakura ovq","description":"phper | golanger | sakuraovq","author":"sakura ovo","url":"https://www.sakuraus.cn"},"pages":[{"title":"404 Not Found _(:з」∠)_","date":"2018-11-01T15:11:05.653Z","updated":"2018-11-01T15:11:05.650Z","comments":true,"path":"/404.html","permalink":"https://www.sakuraus.cn//404.html","excerpt":"","text":""},{"title":"categories","date":"2018-08-05T07:57:10.000Z","updated":"2018-08-19T06:18:15.000Z","comments":false,"path":"categories/index.html","permalink":"https://www.sakuraus.cn/categories/index.html","excerpt":"","text":""},{"title":"","date":"2018-10-31T12:28:20.143Z","updated":"2018-10-31T12:28:20.137Z","comments":false,"path":"tags/index.html","permalink":"https://www.sakuraus.cn/tags/index.html","excerpt":"","text":""}],"posts":[{"title":"docker-machine","slug":"docker-machine","date":"2018-11-02T08:44:55.127Z","updated":"2018-11-02T08:44:55.127Z","comments":true,"path":"2018/11/02/docker-machine/","link":"","permalink":"https://www.sakuraus.cn/2018/11/02/docker-machine/","excerpt":"","text":"docker-machine Docker Machine 介绍为什么需要Docker Machine Docker Machine 介绍 Docker Machine 是 Docker 官方编排项目之一，负责在多种平台上快速安装 Docker 环境。 Docker Machine 是一个工具，它允许你在虚拟宿主机上安装 Docker Engine ，并使用 docker-machine 命令管理这些宿主机。你可以使用 Machine 在你本地的 Mac 或 Windows box、公司网络、数据中心、或像 阿里云 或 华为云这样的云提供商上创建 Docker 宿主机。 使用 docker-machine 命令，你可以启动、审查、停止和重新启动托管的宿主机、升级 Docker 客户端和守护程序、并配置 Docker 客户端与你的宿主机通信 为什么要使用它？ 在没有Docker Machine之前，你可能会遇到以下问题： 1、你需要登录主机，按照主机及操作系统特有的安装以及配置步骤安装Docker，使其能运行Docker容器。 2、你需要研发一套工具管理多个Docker主机并监控其状态。Docker Machine的出现解决了以上问题。 1、Docker Machine简化了部署的复杂度，无论是在本机的虚拟机上还是在公有云平台，只需要一条命令便可搭建好Docker主机 2、Docker Machine提供了多平台多Docker主机的集中管理部署 3、Docker Machine 使应用由本地迁移到云端变得简单，只需要修改一下环境变量即可和任意Docker主机通信部署应用。 Docker的组成： 1、Docker daemon 2、一套与 Docker daemon 交互的 REST API 3、一个命令行客户端 docker-machine 安装1curl -L https://github.com/docker/machine/releases/download/v0.14.0/docker-machine-`uname -s`-`uname -m` &gt;/tmp/docker-machine &amp;&amp; \\&gt; install /tmp/docker-machine /usr/local/bin/docker-machine 使用 用Docker Machine可以批量安装和配置docker host，其支持在不同的环境下安装配置docker host，包括： 常规 Linux 操作系统 虚拟化平台 - VirtualBox、VMWare、Hyper-V 公有云 - Amazon Web Services、Microsoft Azure、Google Compute Engine、阿里、华为等 普通方式，仅供参考 创建一个名为cluster-master1 的主机，驱动方式是virtualbox1docker-machine create --driver virtualbox cluster-master1 报错提示没有发现VBoxManage。因此，需要手工安装 docker-machine 编辑yum 源1vim /etc/yum.repos.d/virtualbox.repo 写入以下信息1234567891011[virtualbox]name=Oracle Linux / RHEL / CentOS-$releasever / $basearch - VirtualBoxbaseurl=http://download.virtualbox.org/virtualbox/rpm/el/$releasever/$basearchenabled=1gpgcheck=0repo_gpgcheck=0gpgkey=https://www.virtualbox.org/download/oracle_vbox.ascyum search VirtualBox #查找具体安装版本yum install VirtualBox 还有可能出现报错内核不一致 根据提示下载指定的版本123yum install kernel-devel-3.10.0-862.2.3.el7.x86_64 yum install VirtualBoxvboxconfig #重新加载执行下，再次创建 继续报错，没有开启虚拟化，云服务器默认是不能开启的，云服务器有云服务器的驱动，目前阿里云、华为云有这种驱动，同时比如阿里云的驱动是可以在腾讯云使用，也可以在本地使用，这个不造成影响。 docker-machine 第三方驱动支持列表 https://github.com/docker/docker.github.io/blob/master/machine/AVAILABLE_DRIVER_PLUGINS.md 第三方驱动使用 1、下载驱动 二进制文件也可用，可以从以下链接下载： Mac OSX 64位： https://docker-machine-drivers.oss-cn-beijing.aliyuncs.com/docker-machine-driver-aliyunecs_darwin-amd64.tgz Linux 64位 : https://docker-machine-drivers.oss-cn-beijing.aliyuncs.com/docker-machine-driver-aliyunecs_linux-amd64.tgz Windows 64位： https://docker-machine-drivers.oss-cn-beijing.aliyuncs.com/docker-machine-driver-aliyunecs_windows-amd64.tgz 2、解压安装1234curl -L https://docker-machine-drivers.oss-cn-beijing.aliyuncs.com/docker-machine-driver-aliyunecs_linux-amd64.tgz tar xzvf driver-aliyunecs.tgz -C docker-machinemv ./bin/docker-machine-driver-aliyunecs.linux-amd64 /usr/local/bin/docker-machine-driver-aliyunecs chmod +x /usr/local/bin/docker-machine-driver-aliyunecs 想要创建一个阿里云虚拟化实例，需要满足几个条件 1、账户余额大于100，因为创建的实例为按量付费 2、设置accesskey，要具备操作账户的权限 阿里云驱动安装 登录阿里云账号控制台https://home.console.aliyun.com/new#/，选择accesskey 12345678docker-machine create -d aliyunecs --aliyunecs-io-optimized=optimized --aliyunecs-description=aliyunecs-machine-driver --aliyunecs-instance-type=ecs.mn4.small --aliyunecs-access-key-id=LTAIJIGa4sFefl1g --aliyunecs-access-key-secret=AlA7CV6zjntg7Q1zO3sGvIMIAxJi3m --aliyunecs-region=cn-hangzhou --aliyunecs-ssh-password=zaq1@wsxmanager –aliyunecs-io-optimized=optimized //磁盘io优化 –aliyunecs-description=aliyunecs-machine-driver //描述 –aliyunecs-instance-type=ecs.mn4.small //实例规格 –aliyunecs-access-key-id=LTxxxcxx // key –aliyunecs-access-key-secret=Axxx //秘钥 –aliyunecs-region=cn-hangzhou //地区 --aliyunecs-ssh-password=zaq1@wsx //ssh登录密码 –aliyunecs-image-id=centos_7_04_64_20G_alibase_201701015.vhd //镜像实例 docker-machine 管理 两台服务器 本地主机：47.98.147.4xx 远程主机：xxx.xxx.xxx Scp操作1docker-machine scp worker:/root/foo.txt . mount 操作云服务器，不能使用（可能） 手册 https://docs.docker.com/machine/install-machine/ 创建dockr虚拟宿主机","categories":[{"name":"docker","slug":"docker","permalink":"https://www.sakuraus.cn/categories/docker/"},{"name":"docker-machine","slug":"docker/docker-machine","permalink":"https://www.sakuraus.cn/categories/docker/docker-machine/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://www.sakuraus.cn/tags/docker/"},{"name":"docker-machine","slug":"docker-machine","permalink":"https://www.sakuraus.cn/tags/docker-machine/"}]},{"title":"docker-swarm","slug":"docker-swarm","date":"2018-11-02T08:41:55.921Z","updated":"2018-11-02T08:41:55.921Z","comments":true,"path":"2018/11/02/docker-swarm/","link":"","permalink":"https://www.sakuraus.cn/2018/11/02/docker-swarm/","excerpt":"","text":"#Docker swarm ##介绍，为什么需要Docker swarm ##Docker swarm 跟docker的关系 ##创建dockr swarm集群实现伸缩调度 一、Docker swarm 介绍 Swarm是Docker公司推出的用来管理docker集群，它将一群Docker宿主机变成一个单一的，虚拟的主机。Swarm使用标准的Docker API接口作为其前端访问入口，换言之，各种形式的Docker Client(docker client in Go, docker_py, docker等)均可以直接与Swarm通信。 Swarm几乎全部用go语言来完成开发，Swarm0.2发布，相比0.1版本，0.2版本增加了一个新的策略来调度集群中的容器，使得在可用的节点上传播它们，以及支持更多的Docker命令以及集群驱动。 Swarm deamon只是一个调度器（Scheduler）加路由器(router)，Swarm自己不运行容器，它只是接受docker客户端发送过来的请求，调度适合的节点来运行容器，这意味着，即使Swarm由于某些原因挂掉了，集群中的节点也会照常运行，当Swarm重新恢复运行之后，它会收集重建集群信息． 结构图： docker_swarm.png 一、为什么要使用它？ 1、应用想要扩容到两台以上的服务器上，多台服务器总是比单台服务器复杂，可以使用docker-swarm进行集群化的管理跟伸缩 2、应用是否有高可用的要求，在docker swarm集群中有两种不同类型的节点，Master节点和Worker节点,其中的一个Master节点是Leader,如果当前Leader宕机不可用，其他健康的Master中的一台会自动成为Leader 。如果Worker节点宕机不可用，宕机节点上的容器实例会被重新调度到其他健康的Worker节点上。 ####一、关键概念 Swarm 集群的管理和编排是使用嵌入到docker引擎的SwarmKit，可以在docker初始化时启动swarm模式或者加入已存在的swarm Node 运行 Docker 的主机可以主动初始化一个 Swarm 集群或者加入一个已存在的 Swarm 集群，这样这个运行 Docker 的主机就成为一个 Swarm 集群的节点 ( node ) 节点分为管理 ( manager ) 节点和工作 ( worker ) 节点。 管理节点用于 Swarm 集群的管理， docker swarm 命令基本只能在管理节点执行（节点退出集群命令 docker swarm leave 可以在工作节点执行）。 一个 Swarm 集群可以有多个管理节点，但只有一个管理节点可以成为 leader ， leader 通过 raft 协议实现 工作节点是任务执行节点，管理节点将服务 ( service ) 下发至工作节点执行。管理节点默认也作为工作节点。你也可以通过配置让服务只运行在管理节点。 docker_swarm_node 服务和任务 任务 （ Task ）是 Swarm 中的最小的调度单位，目前来说就是一个单一的容器。 服务 （ Services ） 是指一组任务的集合，服务定义了任务的属性。 docker_swarm_relation ###docker swarm init 命令参考 docker_swarm_init –cert-expiry设置节点证书有效期 –dispatcher-heartbeat设置节点报告它们的健康状态间隔的时间。 –external-ca value设置集群使用一个外部CA来签发节点证书。value的格式为protocol=X,url=Y。protocol指定的是发送签名请求到外部CA所使用的协议。目前只支持cfssl。URL指定的是签名请求应该提交到哪个endpoint。 –force-new-cluster强制一个失去仲裁能力的集群的其中一个节点重启成为一单节点集群，而不丢失数据。 –listen-addr value在这个地址监听集群管理相关流量。默认是监听0.0.0.0:2377。也可以指定一个网络接口来监听这个接口的地址。例如–listen-addr eth0:2377。端口是可选的。如果仅指定IP地址或接口名称，端口就使用默认的2377。 –advertise-addr value指定通告给集群的节点的地址，这个地址用来给其它节点访问API和overlay网络通信。如果没有指定地址，docker将检查系统是否只有一个IP地址，如果是将使用这个地址并使用监听的端口(查看–listen-addr)。如果系统有多个IP地址，–advertise-addr就必须指定一个以便内部管理节点能够正常通信和overlay网络通信。也可以指定一个网络接口来通告接口的地址，例如–advertise-addr eth0:2377。端口是可选的。如果仅指定一个IP地址或接口名称，就使用端口2377。 –task-history-limit设置任务历史记录保留限制。1、初始化1docker swarm init --advertise-addr xx.xx.xx 2、加入集群12 docker swarm join-token worker #可以查看加入节点的tokendocker swarm join --token SWMTKN-1-1oxfayeqathm39flfmtuglt3l3xpdkemellw8iyom0h99h5ebu-e4tfrqla6uqgzjgo1r4t84rtt 47.98.109.204:2377 3、查看节点1docker node ls 4、部署服务在manager节点部署nginx服务，服务数量为10个，公开指定端口是8080映射容器80,使用nginx镜像1docker service create --replicas 3 -p 80:80 --name nginx nginx","categories":[{"name":"docker","slug":"docker","permalink":"https://www.sakuraus.cn/categories/docker/"},{"name":"docker-swarm","slug":"docker/docker-swarm","permalink":"https://www.sakuraus.cn/categories/docker/docker-swarm/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://www.sakuraus.cn/tags/docker/"},{"name":"docker-swarm","slug":"docker-swarm","permalink":"https://www.sakuraus.cn/tags/docker-swarm/"}]},{"title":"gitlab部署必须条件","slug":"gitlab部署","date":"2018-10-31T13:13:32.356Z","updated":"2018-08-19T06:37:16.000Z","comments":true,"path":"2018/10/31/gitlab部署/","link":"","permalink":"https://www.sakuraus.cn/2018/10/31/gitlab部署/","excerpt":"","text":"gitlab部署必须条件 代码必须外部挂载，单独保存，不因为容器或者机器的释放而丢失 必须自定义域名 能使用邮箱发送功能 最好是中文的 详细部署步骤NAS 创建文件存储服务NAS，利用文件存储服务来满足代码不因容器和机器的释放而丢失 文件存储服务-创建 NFS 文件系统 创建一个挂载点 容器服务-数据卷-创建一个数据卷，名称为gitlab，其他参数使用上面创建的挂载点参数这样我们就创建了一个单独数据卷来保存我们文件，只要部署时把这个数据卷映射到数据文件上就OK了。 邮箱 申请163邮箱账号用于邮件发送申请成功后，注意开通POP3,SMTP功能，拿到授权码 SLB 创建集群，设置SLB 名称为 gitlab_com 编排 创建自定义编排文件1234567891011121314151617gitlab: image: &apos;twang2218/gitlab-ce-zh:latest&apos; ports: - &apos;80&apos; - &apos;10012:22&apos; - &apos;443&apos; restart: always environment: - &apos;GITLAB_OMNIBUS_CONFIG=external_url &apos;&apos;http://gitlab.lingdianit.com&apos;&apos;;gitlab_rails[&apos;&apos;smtp_enable&apos;&apos;] = true;gitlab_rails[&apos;&apos;smtp_address&apos;&apos;] = &quot;smtp.163.com&quot;;gitlab_rails[&apos;&apos;smtp_port&apos;&apos;] = 25;gitlab_rails[&apos;&apos;smtp_user_name&apos;&apos;] = &quot;gitlablingdian@163.com&quot;;gitlab_rails[&apos;&apos;smtp_password&apos;&apos;] = &quot;tuandui1234&quot;;gitlab_rails[&apos;&apos;smtp_domain&apos;&apos;] = &quot;163.com&quot;;gitlab_rails[&apos;&apos;smtp_authentication&apos;&apos;] = &quot;login&quot;;gitlab_rails[&apos;&apos;smtp_enable_starttls_auto&apos;&apos;] = true;gitlab_rails[&apos;&apos;gitlab_email_from&apos;&apos;] = &quot;gitlablingdian@163.com&quot;;user[&quot;git_user_email&quot;] = &quot;gitlablingdian@163.com&quot;;&apos; labels: aliyun.probe.url: &apos;tcp://container:80&apos; aliyun.probe.initial_delay_seconds: &apos;10&apos; aliyun.scale: &apos;1&apos; aliyun.routing.port_80: &apos;http://gitlab.lingdianit.com&apos; aliyun.lb.port_22: &apos;tcp://gitlab_com:22&apos; volumes: - &apos;gitlab:/var/opt/gitlab:rw&apos; 编排文件中注意点 enviroment GITLAB_OMNIBUS_CONFIG 建议使用图形页面添加,前面填写 GITLAB_OMNIBUS_CONFIG ,后面格式为 1external_url &apos;http://gitlab.lingdianit.com&apos;;gitlab_rails[&apos;smtp_enable&apos;] = true;gitlab_rails[&apos;smtp_address&apos;] = &quot;smtp.163.com&quot;;gitlab_rails[&apos;smtp_port&apos;] = 25;gitlab_rails[&apos;smtp_user_name&apos;] = &quot;gitlablingdian@163.com&quot;;gitlab_rails[&apos;smtp_password&apos;] = &quot;tuandui1234&quot;;gitlab_rails[&apos;smtp_domain&apos;] = &quot;163.com&quot;;gitlab_rails[&apos;smtp_authentication&apos;] = &quot;login&quot;;gitlab_rails[&apos;smtp_enable_starttls_auto&apos;] = true;gitlab_rails[&apos;gitlab_email_from&apos;] = &quot;gitlablingdian@163.com&quot;;user[&quot;git_user_email&quot;] = &quot;gitlablingdian@163.com&quot;; 类似上面这个格式，如果你需要更改其他参数，请参考gitlab官方 容器路由的问题 实现http很简单，只需这么一句 'http://gitlab.lingdianit.com' ```123456表示容器的80端口，映射到这个域名,多域名可用 ; 分割暴露22端口问题，我们需要用到 自定义负载均衡的 lb 标签下面举个例子，简单讲述下这个自定义 lb的理解 aliyun.lb.port_22: &apos;tcp://gitlab_com:22&apos; 123456789101112 第一个端口22,是容器的端口 ,第二个端口22 指的是 gitlab_com 的 slb 前端端, 负载均衡的后端端口 应该是主机的端口，这时到文件中去查找 22 对应主机端口是 10012, 所以负载均衡22 的后端端口应该是10012,自己在负载均衡上添加一条22:10012 记录 ### 使用编排文件部署应用### 集群管理，使用本地管理集群- 下载证书 集权-管理-下载证书- 本地配置 建立使用别名，添加到 .bashrc alias docker-private=’docker –tlsverify –tlscacert=/Users/xufei/aliyun/private/ca.pem –tlscert=/Users/xufei/aliyun/private/cert.pem –tlskey=/Users/xufei/aliyun/private/key.pem -H=tcp://master4g5.cs-cn-hangzhou.aliyun.com:21004’ source .bashrc docker-private ps //就能查看集群所有容器了` 其他注意概念 应用一个应该可包含多个服务 服务应用的组成部分 节点集群的机器节点，有时需要彻底清理机器，可以使用重置节点，会清空整个磁盘 数据集我们主动创建的数据卷 或者 容器内部 主动暴露 的 volume ,有时我们需要重新部署，建议主动删除数据集，不然以前的数据，配置信息总还在 相关信息 gitlab中文镜像-https://github.com/twang2218/gitlab-ce-zh gitlabce-官方docker指南 gitlabce-所有配置项简介 阿里云-自定义lb标签简介 gitlab-163邮箱配置","categories":[{"name":"gitlab","slug":"gitlab","permalink":"https://www.sakuraus.cn/categories/gitlab/"}],"tags":[{"name":"gitlab","slug":"gitlab","permalink":"https://www.sakuraus.cn/tags/gitlab/"}]},{"title":"设计模式之 facade 模式","slug":"facade","date":"2018-10-31T13:13:31.915Z","updated":"2018-08-19T06:20:51.000Z","comments":true,"path":"2018/10/31/facade/","link":"","permalink":"https://www.sakuraus.cn/2018/10/31/facade/","excerpt":"","text":"laravel 框架实现的门面模式 什么是门面模式,在我的理解范围中主要为对象提供高级接口 为什么要使用门面模式, 在传统开发中最难过就是文件迁移 现在都是基于命名空间开发的框架,一旦文件迁移的了 use这个类的文件都需要修改提升了维护成本,也限制了可扩展性 在使用门面模式之后我们为一个公共类型实现一个高级接口外部调用,只需要引入门面既可以调用 实现第一步需要为类提供给门面在laravel框架中首先需要定义自己的facade 然后可以在app.php的配置文件中alias别名中映射门面相当于给门面给了一个别名 通过 static 获取上下文环境获取外观模式中的 别名 然后通过 反转获取到 Ioc 容器中的实例 __callStatic()实现调用 静态延迟绑定","categories":[{"name":"laravel","slug":"laravel","permalink":"https://www.sakuraus.cn/categories/laravel/"}],"tags":[{"name":"设计模式","slug":"设计模式","permalink":"https://www.sakuraus.cn/tags/设计模式/"},{"name":"php","slug":"php","permalink":"https://www.sakuraus.cn/tags/php/"},{"name":"laravel","slug":"laravel","permalink":"https://www.sakuraus.cn/tags/laravel/"}]},{"title":"如何搭建一个微服务架构","slug":"docker-compose","date":"2018-10-31T13:13:31.679Z","updated":"2018-09-02T04:28:18.000Z","comments":true,"path":"2018/10/31/docker-compose/","link":"","permalink":"https://www.sakuraus.cn/2018/10/31/docker-compose/","excerpt":"","text":"docker-compose术语 服务 ( service )：一个应用容器，实际上可以运行多个相同镜像的实例。 项目 ( project )：由一组关联的应用容器组成的一个完整业务单元。 可见，一个项目可以由多个服务（容器）关联而成， Compose 面向项目进行管理。 Dockerfile dockerfile是构建镜像的一个语法文件 类似shell 脚本 的语法 详情参考docker docker-compose 是可以构建多个服务的编排文件 现在有几个版本的编排语法 基本都是兼容的主要高版本加了一些新语法 使用高版本的时候注意docker版本 下面我列举出构建一个示例123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128version: &quot;2&quot; #不同版本支持的语法不同具services: #服务 编排的好处在于不用手动的去一次运行镜像 实现自动化docker很轻松就能部署一个项目 swoft1: # 服务名称 container_name: swoft-server1 # 运行的容器名称 image: swofts # 指定为镜像名称或镜像 ID。如果镜像在本地不存在， Compose 将会尝试拉取这个镜像。 ports: # 暴露端口信息 前面对应宿主机的端口 : 后面对应容器里面开放的端口 - &quot;8003:9502&quot; - &quot;8004:9504&quot; - &quot;8005:8099&quot; links: # 容器依靠的其他服务 这种方式是通过查询同一个网络中的服务 - db - redis - consul-client volumes: # 共享卷 前面对应宿主机的地址:后面把宿主机的地址映射到容器里面的地址 - /www/swoft:/var/www/swoft stdin_open: true # network_mode: &quot;mynetwork&quot; #设置网络模式。使用和 docker run 的 --network 参数一样的值。 tty: true # 模拟一个伪终端 command: [/bin/bash] # 覆盖容器启动后默认执行的命令。 swoft2: container_name: swoft-server2 image: swofts ports: - &quot;8006:9502&quot; - &quot;8007:9504&quot; - &quot;8008:8099&quot; links: - db - redis - consul-client volumes: - /www/swoft:/var/www/swoft stdin_open: true network_mode: &quot;mynetwork&quot; tty: true command: [/bin/bash] redis: container_name: redis image: redis ports: - &quot;6378:6379&quot; volumes: - /etc/redis.conf:/usr/local/etc/redis/redis.conf network_mode: &quot;mynetwork&quot; db: container_name: mysql image: mysql:5.7 environment: MYSQL_ROOT_PASSWORD: 123456 ports: - &quot;3307:3306&quot; network_mode: &quot;mynetwork&quot; consul-server: container_name: consul-server image: consul ports: - &quot;32240:8300&quot; - &quot;32241:8301&quot; - &quot;32242:8301/udp&quot; - &quot;32243:8302/udp&quot; - &quot;32244:8302&quot; - &quot;32245:8500&quot; - &quot;32246:8600&quot; - &quot;32247:8600/udp&quot; stdin_open: true network_mode: &quot;mynetwork&quot; tty: true command: /bin/bash consul-server1: container_name: consul-server1 image: consul ports: - &quot;32252:8300&quot; - &quot;32253:8301&quot; - &quot;32254:8301/udp&quot; - &quot;32255:8302/udp&quot; - &quot;32256:8302&quot; - &quot;32257:8500&quot; - &quot;32258:8600&quot; - &quot;32259:8600/udp&quot; links: - consul-server stdin_open: true network_mode: &quot;mynetwork&quot; tty: true command: /bin/bash consul-server2: container_name: consul-server2 image: consul ports: - &quot;32260:8300&quot; - &quot;32261:8301&quot; - &quot;32262:8301/udp&quot; - &quot;32263:8302/udp&quot; - &quot;32264:8302&quot; - &quot;32265:8500&quot; - &quot;32266:8600&quot; - &quot;32267:8600/udp&quot; links: - consul-server stdin_open: true network_mode: &quot;mynetwork&quot; tty: true command: /bin/bash consul-client: container_name: consul-client image: consul ports: - &quot;32270:8300&quot; - &quot;32271:8301&quot; - &quot;32272:8301/udp&quot; - &quot;32273:8302/udp&quot; - &quot;32274:8302&quot; - &quot;32275:8500&quot; - &quot;32276:8600&quot; - &quot;32277:8600/udp&quot; links: - consul-server - consul-server1 - consul-server2 stdin_open: true network_mode: &quot;mynetwork&quot; tty: true command: /bin/bash PHP环境搭建、win7系统 一、docker软件的下载1、下载地址:https://www.docker.com/docker-windows2、安装docker文件，直接点击下一步操作，完成后会自动安装VM和Git这两个文件。 ①安装过程中，会出现找不到，boot2docker这个文件，这个文件是docker的依赖，需要下载拷贝到docker的指定文件目录，(在报错位置)。 ②安装过程中出现enter press contiune … 情况，需要重启系统，按F2进入配置IO环境。更改配置。3、安装完成后，docker会自动分配一个IP地址，默认的帐号和密码，使用Xshell进行连接操作。(帐号:docker，密码:tcuser)4、以上连接完成后，进行镜像拉取，使用命令:docker pull 镜像名称，把镜像进行本地映射。5、运行镜像，使用命令:docker run -i -t 镜像名称 /bin/bash 如果出错，按出错提示进行操作。6、docker run -d -v /data:/data -p 80:80 -p 1229:1229 registry.aliyuncs.com/lingdianit/dev:v3 /etc/rc.local //运行映射文件及端口，这里的配置，必须要和虚拟机中的映射文件一致,data/7、常用命令的使用。 docker -version //查看版本 docker pull/push/search 镜像名称 //下载/上传/搜索镜像文件 docker images //列出所有安装过的镜像。 docker start/stop/run/resart/kill 进程id //docker启动/停止/运行/重启/杀掉 如:docker start a62 docker ps //查看映射文件 二、Xshell软件的下载 Xshell主要使用的是连接docker。方便命令操作。 三、VM虚拟机的环境映射1、本地磁盘中建立一个文件夹，后面需要映射的文件目录。2、启动docker时就已经启动VM虚拟机，在启动过程中有如下设置： 设置-&gt;共享文件价-&gt;添加共享文件-&gt;文件路径和文件目录(路径是本地文件的目录，文件目录是需要映射到虚拟机中的目录)。设置完成后需要重启虚拟机后生效。3、重启Xshell，查看文件夹中映射的文件是否存在，存在则配置成功。未配置成功查看错误日志。 四、域名的绑定设置 域名配置。C:\\Windows\\System32\\drivers\\etc\\hosts.txt,如下配置: 192.168.99.100 www.keloop.cn 192.168.99.100 staitc.keloop.cn 说明：前面是docker分配的IP地址，后面是配置访问的域名。 五、Git版本控制代码命令 1、使用SSH模式进行操作 2、全局配置： git config –global user.name “用户名” git config –global user.email 邮箱地址 3、常见命令 git init . //初始化 git add newfile //提交新文件到暂存区 git commit -m ‘add new file’ //提交到本地仓库 git remote add origin git@xx.com:demo.git //添加远程仓库地址 git fetch origin -p // 同步本地远程仓库镜像 git push origin dev:dev //把本地dev 推送到远端 git br dev //创建本地dev分支 git br feature-new origin/dev // 基于远端dev 创建新分支 feature-new git checkout -b feature-coupon origin/dev //创建分支 switched to a new branch “feature-coupon” //切换分支 git merge origin/dev //合并远端dev分支 密钥生成及配置(仓库和本地密钥必须一致) ssh-keygen -t rsa //生成密钥，产生id_rsa和id_rsa.pub 本地密钥放在:C:\\Users\\Administrator\\.ssh\\ gitlab设置密钥：设置-&gt;SSH密钥-&gt;添加密钥","categories":[{"name":"docker","slug":"docker","permalink":"https://www.sakuraus.cn/categories/docker/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://www.sakuraus.cn/tags/docker/"},{"name":"docker-compose","slug":"docker-compose","permalink":"https://www.sakuraus.cn/tags/docker-compose/"},{"name":"MicroService","slug":"MicroService","permalink":"https://www.sakuraus.cn/tags/MicroService/"}]},{"title":"镜像发布","slug":"应用发版规范","date":"2018-10-31T13:13:31.449Z","updated":"2018-08-19T06:39:45.000Z","comments":true,"path":"2018/10/31/应用发版规范/","link":"","permalink":"https://www.sakuraus.cn/2018/10/31/应用发版规范/","excerpt":"","text":"测试,上版制度web端的测试 主要在二刀环境进行测试 三刀除了进行功能测试,还需要进行回归测试 大的改动一定要提前进行测试,如果存在数据恢复的问题,需要提前进行演练 客户端的测试 客户端包括电脑端+移动端，上版本之前的测试阶段分为三步，依次是：技术部内测、公司全部门内测、分时间段公测。其中技术部内测，需将测试包发给产品助理以及上传测试平台testin进行测试。 安卓和IOS工程师需获取全部APP下载人群所使用的手机版本，根据数据来决定最低兼容的手机系统版本号 上版时间规定所有系统的更新上版时间不能在周末节假日前一天，不能在订单高峰期时间。严格控制在早上10点以前，下午4点以前，超过规定时间则不予更新，十分紧急情况除外。 上版代码管理情况 一般分为dev,release,master分支 上版使用release分支，一定要实际在三刀测试release分支，最后推送到master分支前，需要对release分支打上tag 上版以后要观察日志 关于二刀测试环境与三刀预上线环境说明二刀环境完全搭建一套独立环境,使用独立数据库,独立队列,完全模拟整个平台的运行 数据库 xx_test队列 xx_test 三刀预上线环境使用生产环境数据库 使用独立队列","categories":[{"name":"上线","slug":"上线","permalink":"https://www.sakuraus.cn/categories/上线/"}],"tags":[{"name":"images","slug":"images","permalink":"https://www.sakuraus.cn/tags/images/"}]},{"title":"Api约束","slug":"应用程序API约定","date":"2018-10-31T13:13:31.221Z","updated":"2018-08-19T06:39:45.000Z","comments":true,"path":"2018/10/31/应用程序API约定/","link":"","permalink":"https://www.sakuraus.cn/2018/10/31/应用程序API约定/","excerpt":"","text":"通用约定 所有编码都采用UTF-8 日期格式采用yyyy-MM-dd方式，如2015-08-10 Content-type为application/json; charset=UTF-8 公共请求头 头域（Header） 是否必须 说明 Authorization 必须 包含Access Key与请求签名 Host 必须 包含API的域名 Content-Type 可选 application/json; charset=utf-8 公共响应头 头域(Header) 说明 Content-Type 只支持JSON格式，application/json; charset=utf-8 响应状态码可使用 HTTP Status Codes RFC7231，同时使用消息自定义的code来做业务处理 通用错误返回格式当调用接口出错时，将返回通用的错误格式返回的消息体将包括全局唯一的请求、错误代码以及错误信息。调用方可根据错误码以及错误信息,requestid以便于快速地帮助您解决问题定位问题。 消息体定义 参数名 类型 说明 request_id String 请求的唯一标识 code String 错误类型代码 message String 错误的信息说明 公共错误码每个项目组定义自己的业务code建议以1000开始，定义code的主要意义是看==客户端是否需要根据code来区分这个错误== 签名认证第三方接口认证 AccessKeyId/AccessKeySecret 模型AccessKeyId用于标示用户AccessKeySecret是用户用于加密签名字符串 签名规则 所有请求字符串排序 + timestamp + uniq_nonce timestatmp +-15分钟有效 uniq_nonce +-15 分钟只能使用一次 能防止重放和篡改，但是客户端密钥保存是个问题，特别是web端 临时token，可以解决sk泄露问题 JWT模型注意点： 不能防止重放和篡改攻击 后台需要减少令牌的授权时间，实现客户端无感自动更新令牌 后台需要实现废弃令牌机制，比如用户更改密码，应该废弃以前所发的令牌 令牌提交方式 Head Authorization:token url url&amp;authorization=token 接口跨域问题CORS 授权解决跨域问题子域名可以通过设置 document.domain=parent.com 来取消跨域 接口权限问题统一使用RBAC 接口日志和限流问题在接入层做拦截，实现限流和日志记录 版本通过url来区分 /v1/order/xxx /v2/order/xxx 接口设计名称要求清晰，明了/v1/order/crete/v1/order/updateStatus 协议使用HTTPS method只使用GET,POST, GET 用于查询，其他都用POST 接口通用参数字段过滤 field=id,firstname12345678910[ &#123; &quot;id&quot;: &quot;543abc&quot;, &quot;first_name:&quot;: &quot;John&quot; &#125;, &#123; &quot;id&quot;: &quot;543add&quot;, &quot;first_name:&quot;: &quot;Bob&quot; &#125;] 条件过滤 123是否关联资源 embed=orderitem 表示包含订单明细 [ { “order_id”:’111’, “orderitem”: { ‘food_name’:’test’ } }]123456排序 ```sort=username,-updated_at``` - 降序分页 ``` page=0&amp;size=15 ``` //第一页 15条分页返回 data { ‘count’ =&gt; ‘11’, ‘cur_page’=&gt; 1, ‘data’ =&gt; {…}}1234经常使用的、复杂的查询标签化，降低维护成本。``` GET /trades?status=closed&amp;sort=created,desc 缩写 GET /trades#recently-closed","categories":[{"name":"Api","slug":"Api","permalink":"https://www.sakuraus.cn/categories/Api/"}],"tags":[{"name":"api","slug":"api","permalink":"https://www.sakuraus.cn/tags/api/"}]},{"title":"Mysql规范","slug":"数据库规范","date":"2018-10-31T13:13:30.249Z","updated":"2018-08-19T06:39:45.000Z","comments":true,"path":"2018/10/31/数据库规范/","link":"","permalink":"https://www.sakuraus.cn/2018/10/31/数据库规范/","excerpt":"","text":"数据库规范基础规范必须使用InnoDB存储引擎 支持事务、行级锁、并发性能更好、CPU及内存缓存页优化使得资源利用率更高 必须使用UTF8字符集,新库默认使用utf8mb4字符集 万国码，无需转码，无乱码风险，节省空间 数据表、数据字段必须加入中文注释 禁止使用存储过程、视图、触发器、Event 高并发大数据的互联网业务，架构设计思路是“解放数据库CPU，将计算转移到服务层”，并发量大的情况下，这些功能很可能将数据库拖死，业务逻辑放到服务层具备更好的扩展性，能够轻易实现“增机器就加性能”。数据库擅长存储与索引，CPU计算还是上移吧 禁止存储大文件或者大照片 大文件和照片存储在文件系统，数据库里存URI多好 命名规范只允许使用内网域名，而不是ip连接数据库线上环境、开发环境、测试环境数据库内网域名遵循命名规范 业务名称：yprinter 本地环境：yprinter_local 测试环境：yprinter_test 线上环境：yprinter_pro 从库在名称后加-s标识，备库在名称后加-ss标识 线上从库：yprinter_pro-s 线上备库：yprinter_pro-ss 库名、表名、字段名：小写，下划线风格，不超过32个字符，必须见名知意，禁止拼音英文混用表名t_xxx，非唯一索引名idx_xxx，唯一索引名uniq_xxx 表设计规范单实例表数目必须小于500单表列数目必须小于30表必须有主键，例如自增主键 主键递增，数据行写入可以提高插入性能，可以避免page分裂，减少表碎片提升空间和内存的使用 主键要选择较短的数据类型， Innodb引擎普通索引都会保存主键的值，较短的数据类型可以有效的减少索引的磁盘空间，提高索引的缓存效率 无主键的表删除，在row模式的主从架构，会导致备库夯住 禁止 使用外键，如果有外键完整性约束，需要应用程序控制：外键会导致表与表之间耦合，update与delete操作都会涉及相关联的表，十分影响sql的性能，甚至造成死锁。大数据高并发业务场景下数据使用以性能优先 字段设计规范必须把字段定义为NOT NULL并且提供默认值 null的列使索引/索引统计/值比较都更加复杂，对MySQL来说更难优化 null 这种类型MySQL内部需要进行特殊处理，增加数据库处理记录的复杂性；同等条件下，表中有较多空字段的时候，数据库的处理性能会降低很多 null值需要更多的存储空，无论是表还是索引中每行中的null的列都需要额外的空间来标识 对null 的处理时候，只能采用is null或is not null，而不能采用=、in、&lt;、&lt;&gt;、!=、not in这些操作符号。如：where name!=’shenjian’，如果存在name为null值的记录，查询结果就不会包含name为null值的记录 合理使用TEXT、BLOB类型 TEXT,BLOB类型数据请使用垂直分表,把这类数据分离开来, 禁止使用小数存储货币 使用整数吧，小数容易导致钱对不上 必须使用varchar(20)存储手机号 涉及到区号或者国家代号，可能出现+-() 手机号会去做数学运算么? varchar可以支持模糊查询，例如：like“138%” 访问频率较低的大字段拆分出数据表 详情 并不需要一定遵守范式理论，适度的冗余，让Query尽量减少Join 禁止使用ENUM，可使用TINYINT代替 增加新的ENUM值要做DDL操作 ENUM的内部实际存储就是整数，你以为自己定义的是字符串 索引设计规范单表索引建议控制在5个以内单索引字段数不允许超过5个禁止在更新十分频繁、区分度不高的属性上建立索引 更新会变更B+树，更新频繁的字段建立索引会大大降低数据库性能 “性别”这种区分度不大的属性，建立索引是没有什么意义的，不能有效过滤数据，性能与全表扫描类似 建立组合索引，必须把区分度高的字段放在前面 在order by或者group by子句中，如果想通过索引来进行排序，所建索引列的顺序必须与order by或者group by子句的顺序一致，并且所有列的排序方向（倒序或者正序）都一样 联合索引中的字段应尽量满足过滤数据从多到少的顺序，也就是说差异最大的字段应该房子第一个字段 SQL使用规范禁止使用SELECT *，只获取必要的字段，需要显示说明列属性 读取不需要的列会增加CPU、IO、NET消耗 不能有效的利用覆盖索引 使用SELECT *容易在增加或者删除字段后出现程序BUG 禁止使用INSERT INTO t_xxx VALUES(xxx)，必须显示指定插入的列属性 容易在增加或者删除字段后出现程序BUG 禁止使用属性隐式转换 解读：SELECT uid FROM t_user WHERE phone=13812345678 会导致全表扫描，而不能命中phone索引， phone是varchar类型，SQL语句带入的是整形，故不会命中索引，加个引号就好了： SELECT uid FROM t_user WHERE phone=’13812345678’ 禁止在WHERE条件的属性上使用函数或者表达式 SELECT uid FROM t_user WHERE from_unixtime(day)&gt;=’2017-02-15’ 会导致全表扫描 正确的写法是：SELECT uid FROM t_user WHERE day&gt;= unix_timestamp(‘2017-02-15 00:00:00’) 禁止负向查询，以及%开头的模糊查询 负向查询条件：NOT、!=、&lt;&gt;、!&lt;、!&gt;、NOT IN、NOT LIKE等，会导致全表扫描 %开头的模糊查询，会导致全表扫描 禁止大表使用JOIN查询，禁止大表使用子查询禁止使用OR条件，必须改为IN查询应用程序必须捕获SQL异常，并有相应处理 select * from student where name=’you’ or name=’me’ or name=’he’ 可以改成 select * from student where name in (‘you’,’me’,’he’); 补充禁止使用应用程序配置文件内的帐号手工访问线上数据库开发、测试、线上环境隔离数据库状态字段选择尽量不要使用0，php本身对0判断不友好 时间字段的选择 timestamp,datetime,int 最主要的区别-受时区影响不同。timestamp会跟随设置的时区变化而变化，而datetime保存的是绝对值不会变化。 占用存储空间不同。timestamp储存占用4个字节，datetime储存占用8个字节 可表示的时间范围不同。timestamp可表示范围:1970-01-01 00:00:00~2038-01-09 03:14:07，datetime支持的范围更宽1000-01-01 00:00:00 ~ 9999-12-31 23:59:59 索引速度不同。timestamp更轻量，索引相对datetime更快。 使用时间戳的唯一考虑是：你的应用是否涉及多时区，时间数据是否和时区相关。如果回答“是”，那么就必须使用时间戳，没有任何第二方案。如果不涉及,建议使用timestamp显示更直观 每个表增加create_time、update_time两个字段 分别表示写入时间以及最后更新时间 业务上可能用不到,但是对日常运维管理则非常有用 可以用来判断哪些是可以归档的老数据,定期进行归档 用来做自定义的差异备份也很方便 参考链接58到家数据库30条军规解读 再议数据库军规 时间戳的选择 阿里数据库优化 mysql优化","categories":[{"name":"Mysql","slug":"Mysql","permalink":"https://www.sakuraus.cn/categories/Mysql/"}],"tags":[{"name":"mysql","slug":"mysql","permalink":"https://www.sakuraus.cn/tags/mysql/"},{"name":"范式","slug":"范式","permalink":"https://www.sakuraus.cn/tags/范式/"}]},{"title":"开发流程","slug":"快跑者基本开发流程","date":"2018-10-31T13:13:30.015Z","updated":"2018-08-19T06:39:45.000Z","comments":true,"path":"2018/10/31/快跑者基本开发流程/","link":"","permalink":"https://www.sakuraus.cn/2018/10/31/快跑者基本开发流程/","excerpt":"","text":"新的功能模块基本开发流程 首先，应该熟悉业务需求，了解功能逻辑，明确接口应该接受什么参数，进行什么处理以及返回什么结果 确定具体的业务逻辑，发现未知的逻辑漏洞，避免开发到一半的时候才发现逻辑上有问题 基于以下 demo 开发接口代码 Controller method demo: 12345678910111213141516171819202122public function api()&#123; // Stop one：判断接口调用权限 $this-&gt;checkAuthorization($this-&gt;tokenInfo, [UserModel::LOGIN_ADMIN]); // Step two: 获取所有请求的参数 $param1 = I(&apos;get.param1&apos;, &apos;&apos;); $param2 = I(&apos;get.param2&apos;, &apos;&apos;); // Step three: 验证获取到的参数（取值是否正确） if ($param1 &lt;= 0) &#123; apiResponse(CodeModel::ERROR, &apos;param1 参数异常&apos;); &#125; // Step four: 判断权限（比如判断商户和团队是否关联） // Step five: 进行具体的业务逻辑处理（一般会在相应的 Service 中创建一个同名方法进行处理）并返回结果（一般是 Resuful 风格的数据格式） // Step six: 解析返回结果（因为前端需要对返回数据进行一些处理，一般调用 *View::parse*()） // Step serven: 返回最终结果&#125; Service method demo: 12345678910public static function api()&#123; // 进行具体的业务逻辑处理 // 注意：几乎所有数据都进行了缓存，因此如果数据库字段发生变更需要清除之前的缓存 // 一般以 get 开头的方法表示获取数据，以 set/update/modify 等开头的表示更新数据 // 在编写新的功能方法之前，要先看看是否已经存在相同功能的方法&#125; 代码编写完成之后，要先自己 review 一遍，检测代码逻辑、格式是否存在问题 检查完毕之后，自己测试一下接口是否实现目的（返回正确结果和返回错误结果） Ctrl + Alt + L，格式化一下代码（html,js 代码不用格式化） 提交代码，编辑合适的注释，推送到远端，找其他人 review code.","categories":[{"name":"php","slug":"php","permalink":"https://www.sakuraus.cn/categories/php/"}],"tags":[{"name":"code","slug":"code","permalink":"https://www.sakuraus.cn/tags/code/"}]},{"title":"日志记录","slug":"代码日志记录指南","date":"2018-10-31T13:13:29.767Z","updated":"2018-08-19T06:37:16.000Z","comments":true,"path":"2018/10/31/代码日志记录指南/","link":"","permalink":"https://www.sakuraus.cn/2018/10/31/代码日志记录指南/","excerpt":"","text":"日志记录的作用记录事务发生的过程,方便排查问题 日志记录的包含要素 request_id 事务发生唯一标识 time 时间 host 发生所在机器 code_line 事件发生所在代码行数 (分解为 file ,class , line ) message 事件描述 日志记录等级 ERROR 不符合代码预期，出现意外情况,比如: 数据库语句执行失败 WARN 用户输入的数据不符合格式 用户某些操作失败, 比如: 用户登录失败 INFO 关键节点的流程描述 条件分支进入某流程 DEBUG 某个时刻,某个变量的值 SQL语句 日志记录地点程序由三种结构组成:顺序,判断,循环 我们记录的日志要点: 清晰表现我们执行路径和我们这条路径上关注的某些值","categories":[{"name":"Log","slug":"Log","permalink":"https://www.sakuraus.cn/categories/Log/"}],"tags":[{"name":"日志监控","slug":"日志监控","permalink":"https://www.sakuraus.cn/tags/日志监控/"}]},{"title":"第一次写博客 有点紧张 请大家多多关照","slug":"work","date":"2018-10-31T13:13:29.555Z","updated":"2018-08-06T14:01:53.000Z","comments":true,"path":"2018/10/31/work/","link":"","permalink":"https://www.sakuraus.cn/2018/10/31/work/","excerpt":"","text":"Welcome to sakuraus.cn (～￣▽￣)～ Phper,目前在学习Golang,Db,和Docker方面的知识欢迎大家一起讨论","categories":[],"tags":[]},{"title":"Redis开发规范","slug":"Redis开发规范","date":"2018-10-31T13:13:28.884Z","updated":"2018-08-19T06:31:21.000Z","comments":true,"path":"2018/10/31/Redis开发规范/","link":"","permalink":"https://www.sakuraus.cn/2018/10/31/Redis开发规范/","excerpt":"","text":"##Redis开发规范 key名设计1.可读性和可管理性 以业务名(或数据库名)为前缀(防止key冲突)，用冒号分隔，比如业务名:表名:id1ugc:video:1 2.简洁性 保证语义的前提下，控制key的长度，当key较多时，内存占用也不容忽视，例如： 1user:&#123;uid&#125;:friends:messages:&#123;mid&#125;简化为u:&#123;uid&#125;:fr:m:&#123;mid&#125;。 3.不要包含特殊字符 反例：包含空格、换行、单双引号以及其他转义字符 value设计1.拒绝bigkey(防止网卡流量、慢查询) string类型控制在10KB以内，hash、list、set、zset元素个数不要超过5000。 反例：一个包含200万个元素的list。 非字符串的bigkey，不要使用del删除，使用hscan、sscan、zscan方式渐进式删除，同时要注意防止bigkey过期时间自动删除问题(例如一个200万的zset设置1小时过期，会触发del操作，造成阻塞，而且该操作不会不出现在慢查询中(latency可查))，查找方法和删除方法 2.选择适合的数据类型。 例如：实体类型(要合理控制和使用数据结构内存编码优化配置,例如ziplist，但也要注意节省内存和性能之间的平衡) 反例： 12345setuser:1:nametomsetuser:1:age19setuser:1:favor football 正例: 1hmsetuser:1nametomage19favorfootball 3.控制key的生命周期，redis不是垃圾桶。 建议使用expire设置过期时间(条件允许可以打散过期时间，防止集中过期)，不过期的数据重点关注idletime。 命令使用1.O(N)命令关注N的数量 例如hgetall、lrange、smembers、zrange、sinter等并非不能使用，但是需要明确N的值。有遍历的需求可以使用hscan、sscan、zscan代替。 2.禁用命令 禁止线上使用keys、flushall、flushdb等，通过redis的rename机制禁掉命令，或者使用scan的方式渐进式处理。 3.合理使用select redis的多数据库较弱，使用数字进行区分，很多客户端支持较差，同时多业务用多数据库实际还是单线程处理，会有干扰。 4.使用批量操作提高效率12345原生命令：例如mget、mset。非原生命令：可以使用pipeline提高效率。但要注意控制一次批量操作的元素个数(例如500以内，实际也和元素字节数有关)。 注意两者不同：123451. 原生是原子操作，pipeline是非原子操作。2. pipeline可以打包不同的命令，原生做不到3. pipeline需要客户端和服务端同时支持。 5.Redis事务功能较弱，不建议过多使用 Redis的事务功能较弱(不支持回滚)，而且集群版本(自研和官方)要求一次事务操作的key必须在一个slot上(可以使用hashtag功能解决) 6.Redis集群版本在使用Lua上有特殊要求： 123a. 所有key都应该由 KEYS 数组来传递，redis.call/pcall 里面调用的redis命令，key的位置，必须是KEYS array, 否则直接返回error，&quot;-ERR bad lua script for redis cluster, all the keys that the script uses should be passed using the KEYS arrayrn&quot;b. 所有key，必须在1个slot上，否则直接返回error, &quot;-ERR eval/evalsha command keys must in same slotrn&quot; 7.必要情况下使用monitor命令时，要注意不要长时间使用。 客户端使用1.单应用独立redis 避免多个应用使用一个Redis实例 正例：不相干的业务拆分，公共数据做服务化。 2.使用长连接或者连接池 使用带有连接池的数据库，可以有效控制连接，同时提高效率，标准使用方式： 3.【建议】 高并发下建议客户端添加熔断功能(例如netflix hystrix) 4.【推荐】 设置合理的密码，如有必要可以使用SSL加密访问（阿里云Redis支持） 5.【建议】 根据自身业务类型，选好maxmemory-policy(最大内存淘汰策略)，设置好过期时间。 默认策略是volatile-lru，即超过最大内存后，在过期键中使用lru算法进行key的剔除，保证不过期数据不被删除，但是可能会出现OOM问题。 其他策略如下： allkeys-lru：根据LRU算法删除键，不管数据有没有设置超时属性，直到腾出足够空间为止。 allkeys-random：随机删除所有键，直到腾出足够空间为止。 volatile-random:随机删除过期键，直到腾出足够空间为止。 volatile-ttl：根据键值对象的ttl属性，删除最近将要过期数据。如果没有，回退到noeviction策略。 noeviction：不会剔除任何数据，拒绝所有写入操作并返回客户端错误信息”(error) OOM command not allowed when used memory”，此时Redis只响应读操作。 相关工具1.数据同步 redis间数据同步可以使用：redis-port 2.big key搜索 redis大key搜索工具 3.热点key寻找(内部实现使用monitor，所以建议短时间使用) facebook的redis-faina 阿里云Redis已经在内核层面解决热点key问题，欢迎使用。 删除bigkey1.下面操作可以使用pipeline加速。2.redis 4.0已经支持key的异步删除，欢迎使用。1234567a. Hash删除: hscan + hdelb. List删除: ltrimc. Set删除: sscan + sremd. SortedSet删除: zscan + zrem","categories":[{"name":"Redis","slug":"Redis","permalink":"https://www.sakuraus.cn/categories/Redis/"}],"tags":[{"name":"redis","slug":"redis","permalink":"https://www.sakuraus.cn/tags/redis/"}]},{"title":"说明","slug":"README","date":"2018-10-31T13:13:28.670Z","updated":"2018-08-19T06:37:16.000Z","comments":true,"path":"2018/10/31/README/","link":"","permalink":"https://www.sakuraus.cn/2018/10/31/README/","excerpt":"","text":"本项目旨在收集常用规范以及常用最佳实践,方便引导新人和总结,欢迎大家积极提交新文档 代码的合理性规范 前端规范 Git使用指南 PHP开发注意事项 Redis开发规范 数据库设计基本规范 WEB项目常用组成 应用发版规范 讨论和复阅 GITLAB指南 复阅方式 文档 功能的设计和开发说明 日常的最佳实践 测试 单元测试 功能测试 环境统一性,部署环境的可迁移性和统一性(本地,测试,预发布,生产),详见php-demo 数据库版本的统一性 部署 规范 具体部署方法 监控值班规范 值班规范 服务的监控 外部服务的自动监控和报警 内部日志的自动监控和报警 故障快速定位和恢复日志 日志的集中性 日志的快速定位和复现","categories":[],"tags":[]},{"title":"开发注意事项","slug":"php开发注意事项","date":"2018-10-31T13:13:28.180Z","updated":"2018-08-19T06:37:16.000Z","comments":true,"path":"2018/10/31/php开发注意事项/","link":"","permalink":"https://www.sakuraus.cn/2018/10/31/php开发注意事项/","excerpt":"","text":"基本代码规范PHP代码规范 接口开发应用程序api约定 web安全TP安全策略WEB安全 分层常规MVC ,我们把M,进一步拆分 M = dbModel + Service + Cache 具体表现: 数据模型层 + 业务服务成 + 缓存 数据模型层: 只保留db相关字段常量定义和字段验证 业务服务层: 不应该出现任何Session,Cookie 类信息,只专注业务交互,不一定与DB一一对应 异常使用和错误记录问题不建议使用异常,因为有时忘记捕获异常,直接导致程序异常终止 日志记录使用参考(代码日志记录指南)[代码日志记录指南.md] 缓存使用合理使用 内存缓存和静态页面缓存 redis-hash 使用一定要注意key 的数量,数量不要大于1千, 另外一定要及时清理 缓存一定要保证能重建 索引的使用数据量都至少按百万数量级,所以开发过程中一定要主要索引的使用 第三方接口的熔断自动熔断实现 配置实现 代码的测试","categories":[{"name":"分层设计","slug":"分层设计","permalink":"https://www.sakuraus.cn/categories/分层设计/"}],"tags":[{"name":"php","slug":"php","permalink":"https://www.sakuraus.cn/tags/php/"}]},{"title":"PHP基本代码规范","slug":"php后端代码规范","date":"2018-10-31T13:13:27.961Z","updated":"2018-08-19T06:37:16.000Z","comments":true,"path":"2018/10/31/php后端代码规范/","link":"","permalink":"https://www.sakuraus.cn/2018/10/31/php后端代码规范/","excerpt":"","text":"基本代码规范文件 PHP 代码中 必须 使用 &lt;?php ?&gt; 或者 &lt;?= ?&gt;，而不可使用其他标签 所有的 PHP 文件 必须 使用 Unix LF (换行)作为行结束符 只有 PHP 代码的文件关闭标签 ?&gt; 必须 省略 PHP 代码 必须 使用 UTF-8 without BOM 编码 建议每行代码字符数保持在80个以内，理论上不可多于120个，但不做硬性限制 命名 命名空间 Namespace 和类 class 必须 遵循”autoloading” PSR标准: [PSR0,PSR-4]. 类名（class）必须 使用大驼峰命名法，如 StudlyCaps 类中的常量 必须 只能用 大写字母 和 _ 来命名 类中的属性 必须 使用驼峰命名法，如 $camelCase 方法名（method）必须 使用驼峰命名法，如 camelCase PHP 的关键词 keywords 必须 用小写,PHP 中的常量 true，false，null 必须 全部小写 缩进,换行 代码 必须 使用 4个空格 的缩进，而不是制表符 tab,遇到 { 应该进行一次缩进 在 namespace 声明下面 必须 有一个空行，并且 use 声明代码块下面也必须有一个空行 类开始的花括号 必须 放到下一行，结束花括号 必须 放在主体的下一行 方法和控制结构（译者注：for，while 等）开始花括号 必须 放在同一行，结束花括号 必须 放在控制主体的下一行 空行 可以 用来改善可读性和区分相关的代码块,方法与方法之间必须有空行,适当的地方可以添加空行 空格 当进行函数或方法调用的时候，在方法或者函数名与左括号之间 不可 有空格，左括号之后 不可 有空格，右括号之前 不可 有空格, 参数列表中，逗号之前 不可 有空格， $i++ 这种完整体不可有空格 语句结束 ; 不可有空格 其他情况: = , 关键词 与 大括号之间,都应该有空格 代码过长的换行问题 当代码超过80行,建议换行,如参数列表,保留句尾的逗号,下一个参数直接换行,与第一列参数缩4个空格 多条件 &amp;&amp; 作为下一行开始 其他 所有的属性 必须 显式声明可见性,一个语句 不可 声明多个属性 所有的方法 必须 显式声明可见性,abstract 和 final 声明必须在显式声明可见性之前，static 声明必须在显式声明可见性之后,final public static function 所有变量的声明必须显示初始化 代码示例12345678910111213141516switch ($expr) &#123; case 0: echo &apos;First case, with a break&apos;; break; case 1: echo &apos;Second case, which falls through&apos;; // no break case 2: case 3: case 4: echo &apos;Third case, return instead of break&apos;; return; default: echo &apos;Default case&apos;; break;&#125;","categories":[{"name":"PHP","slug":"PHP","permalink":"https://www.sakuraus.cn/categories/PHP/"}],"tags":[{"name":"php","slug":"php","permalink":"https://www.sakuraus.cn/tags/php/"}]},{"title":"","slug":"phpstrom_key","date":"2018-10-31T13:13:27.615Z","updated":"2018-10-13T13:46:26.000Z","comments":true,"path":"2018/10/31/phpstrom_key/","link":"","permalink":"https://www.sakuraus.cn/2018/10/31/phpstrom_key/","excerpt":"","text":"Ctrl+D 复制一行docker run -itd –name redis-master1 -v /test test_1 –net mynetwork -p 6379:6379 –ip 172.10.0.5 redis-mdocker exec -it 471 bash","categories":[],"tags":[]},{"title":"keloop 迭代","slug":"keloop","date":"2018-10-31T13:13:27.091Z","updated":"2018-08-06T12:14:13.000Z","comments":true,"path":"2018/10/31/keloop/","link":"","permalink":"https://www.sakuraus.cn/2018/10/31/keloop/","excerpt":"","text":"keloop 第三次迭代 平台首页 1 平台首页 1.1 基于之前的页面配置之上 添加一个管理分类兼容之前的页面配置 1.2 由于第一版页面配置和平台首页是一对一的关系 需要调整下表结构 1.3 现在迭代的版本需要实现一个平台能有多个平台首页(一对多的关系) 1.4 首先需要在 module 模块 数据表中 添加一个 module_type_id 加一个分类id 1.5 在 module_type 表中记得把 模块排序一起存上 店铺设置 2 店铺设置 2.1 需要添加的字段(店铺大图,店铺业务,支付方式分为平台支付,和店铺自己配置支付) 2.2 店铺相册需要 一个分类表 ,一个类型详情(把平台id和分类id做联合索引) 2.3 如果 店铺业务存放成一个二进制数组 查询列表比较麻烦看到时候是吧分开还是聚合 2.4 其他信息共用之前的数据 2.5 tips:店铺类型固定成常量 数据库存储一个店铺类型就可以了 2.6 店铺配置中的 外送业务 (外卖),开启团购服务必须购买了市场应用才行 2.7 是否预定之前的好像没有配置 如果没有在shop_info中添加一个添加一个是否预定的状态","categories":[],"tags":[]},{"title":"Git基本操作","slug":"git的基本使用","date":"2018-10-31T13:13:26.591Z","updated":"2018-08-19T06:37:16.000Z","comments":true,"path":"2018/10/31/git的基本使用/","link":"","permalink":"https://www.sakuraus.cn/2018/10/31/git的基本使用/","excerpt":"","text":"阅读GIT分支模型 git基本操作步骤 添加用户名 12git config --global user.name &quot;John Doe&quot;git config --global user.email johndoe@example.com 添加常见配置 123456git config --global alias.st statusgit config --global alias.ci commitgit config --global alias.co checkoutgit config --global alias.br branchgit config --global alias.fe fetch -pgit config --global alias.pu push 常用命令 123456789101112131415161718git init . //初始化 git br dev //创建本地dev分支 git add newfile //提交新文件到暂存区 git commit -m &apos;add new file&apos; //提交到本地仓库 git remote add origin git@xx.com:demo.git //添加远程仓库地址 git fetch origin -p // 同步本地远程仓库镜像 git merge origin/dev // 合并远端dev分支 git push origin dev:dev //把本地dev 推送到远端 git br feature-new origin/dev // 基于远端dev 创建新分支 feature-new git add newfeature.txt //提交新文件到暂存区 git ci -m &apos; finish new feature&apos; //提交到本地仓库 git co dev // 切换回本地dev分支 git merge newfeature // 本地dev分钟 合并 newfeature分支 git br -d newfeature // 合并完成,删除 newfeature 分支 git push origin :newfeature // 删除远端 newfeature 分支git fetch origin -p // 同步远端代码到本地 git merge origin/dev // 合并git push origin dev:dev // 推送本地dev到远端dev 冲突解决当二个人同时更改了文件的某些部分,合并时将会出现冲突,此时,可找到另外一个人,仔细对比代码,手动删除不需要的代码,保留合理代码,然后提交两个可能用到的命令 12git checkout --ours conflict.php //使用自己分支的代码,抛弃合并过来冲突git checkout --theirs conflict.php //使用合并分支的代码,抛弃自己冲突这块更改的代码 git 分支使用模型 两大主分支 master 随时都是一个预备生产状态。 生产分支 dev 下个发布版的最新软件变更，每晚自动构建得来 集成分支 辅助性分支 新功能，优化，修复 一般基于dev 分支创建命名 feature-* 创建新功能 12$ git checkout -b feature-coupon origin/devSwitched to a new branch &quot;feature-coupon&quot; 合并新功能到dev 分支 12345678$ git checkout devSwitched to branch &apos;dev&apos;$ git merge --no-ff feature-couponUpdating ea1b82a..05e9557(Summary of changes)$ git branch -d feature-couponDeleted branch feature-coupon (was 05e9557).$ git push origin dev 注意 –no-ff 创建一个新的commit节点 发布分支 当dev分支达到理想的发布状态时，从dev分支来，最后一定要合并到dev和master，命名方式为：release-* release分支是为新产品的发布做准备的。它允许我们在最后时刻做一些细小的修改。 1234567$ git checkout -b release-1.2 devSwitched to a new branch &quot;release-1.2&quot;$ ./bump-version.sh 1.2Files modified successfully, version bumped to 1.2.$ git commit -a -m &quot;Bumped version number to 1.2&quot;[release-1.2 74d9424] Bumped version number to 1.21 files changed, 1 insertions(+), 1 deletions(-) 发布到master 123456$ git checkout masterSwitched to branch &apos;master&apos;$ git merge --no-ff release-1.2Merge made by recursive.(Summary of changes)$ git tag -a 1.2 合并到dev上 12345$ git checkout devSwitched to branch &apos;dev&apos;$ git merge --no-ff release-1.2Merge made by recursive.(Summary of changes) 完成删除 release 12$ git branch -d release-1.2Deleted branch release-1.2 (was ff452fe). 热修复分支 从master来，用于修复线上紧急BUG，命名 hotfix-* 创建新hotfix ，修改版本编号 1234567$ git checkout -b hotfix-1.2.1 masterSwitched to a new branch &quot;hotfix-1.2.1&quot;$ ./bump-version.sh 1.2.1Files modified successfully, version bumped to 1.2.1.$ git commit -a -m &quot;Bumped version number to 1.2.1&quot;[hotfix-1.2.1 41e61bb] Bumped version number to 1.2.11 files changed, 1 insertions(+), 1 deletions(-) 完成hotfix之后，需要把合并到master和dev分支去，这样就可以保证修复的这个bug也包含到下一个发行版中。这一点和完成release分支很相似。合并完成后，删除hotfix分支 git commit 规范 git commit 回答三个问题 修改是什么？ 用什么方法修改的? 这些方法可能影响什么地方? 每次commit只能包含一个改动 每次commit必须单独写提交信息 格式如下 修复client端不能登陆的BUG 以前的方法判断用户唯一错误，少判断用户状态 影响client端用户登陆 git小测试 gitlab.lingdianit.com 使用公司提供qq号注册 项目测试 新建一个项目 ldtest 新建 README.md 文件,里面写清楚 此项目的简介 新建目录doc 创建远程dev,master分支 基于dev,新建新分支 feature-db ,在新分支里面添加 db.txt ,内容任意,推送到远端 feature-db 基于dev,新建新分支 feature-rush, 在新分支里面添加 rush.html, 提交,dev分支合并 featue-rush ,删除 feature-rush,推送dev到远端dev 基于master,新建新分支 hotfix-rush, 在新分支里面添加 rush-fix.html ,master,dev 都合并 hotfix-rush,删除hotfix-rush,dev,master推送对应远端dev,master 参考链接GIT分支模型","categories":[{"name":"Git","slug":"Git","permalink":"https://www.sakuraus.cn/categories/Git/"}],"tags":[{"name":"Git","slug":"Git","permalink":"https://www.sakuraus.cn/tags/Git/"}]},{"title":"gitlab使用简介","slug":"gitlab使用简介","date":"2018-10-31T13:13:26.330Z","updated":"2018-08-19T06:37:16.000Z","comments":true,"path":"2018/10/31/gitlab使用简介/","link":"","permalink":"https://www.sakuraus.cn/2018/10/31/gitlab使用简介/","excerpt":"","text":"gitlab使用简介gitlab地址 https://gitlab.lingdianit.com 使用步骤 使用公司QQ号注册 添加自己电脑公钥 按git的基本使用里面使用 请求合并 领取任务后,新建自己的功能分支 多次提交,完善功能后,把功能分支推送到远端 创建一个请求 合并到dev的申请,请参考git基本使用 分支使用流程 经过二人复阅,合并到dev","categories":[{"name":"gitlab","slug":"gitlab","permalink":"https://www.sakuraus.cn/categories/gitlab/"}],"tags":[{"name":"gitlab","slug":"gitlab","permalink":"https://www.sakuraus.cn/tags/gitlab/"}]},{"title":"Hello World","slug":"hello-world","date":"2018-10-31T10:14:02.665Z","updated":"2018-10-31T10:14:02.665Z","comments":true,"path":"2018/10/31/hello-world/","link":"","permalink":"https://www.sakuraus.cn/2018/10/31/hello-world/","excerpt":"","text":"Welcome to Hexo! This is your very first post. Check documentation for more info. If you get any problems when using Hexo, you can find the answer in troubleshooting or you can ask me on GitHub. Quick StartCreate a new post1$ hexo new \"My New Post\" More info: Writing Run server1$ hexo server More info: Server Generate static files1$ hexo generate More info: Generating Deploy to remote sites1$ hexo deploy More info: Deployment","categories":[],"tags":[]},{"title":"使用github存放markdown所需图片","slug":"markdown-images","date":"2018-09-01T16:00:00.000Z","updated":"2018-09-02T07:08:59.000Z","comments":true,"path":"2018/09/02/markdown-images/","link":"","permalink":"https://www.sakuraus.cn/2018/09/02/markdown-images/","excerpt":"","text":"github存储图片 利用github存储图片，在markdown引用图片链接地址 步骤如下： 自己创建一个公有github仓库 例如 fanyinjiang/markdownImage 先生成 .md 文件 4.点 download 按钮，在地址栏可以复制图片地址，或者在Download按钮上直接右键 “复制链接地址” 拷贝链接地址https://raw.githubusercontent.com/用户名/仓库名/分支/文件名.后缀名 在Markdown中引用图片，![Alt text](图片链接 &quot;optional title&quot;) 插入本地图片 插入本地图片只需要在基础语法的括号中填入图片的位置路径即可，支持绝对路径和相对路径。例如：![avatar](服务器相对路径) 插入网络图片 插入网络图片只需要在基础语法的括号中填入图片的网络链接即可，现在已经有很多免费/收费图床和方便传图的小工具可选。例如：![avatar](http://baidu.com/pic/doge.png)` 把图片存入markdown文件用base64转码工具把图片转成一段字符串，然后把字符串填到基础格式中链接的那个位置。基础用法：![avatar](data:image/png;base64,iVBORw0......)这个时候会发现插入的这一长串字符串会把整个文章分割开，非常影响编写文章时的体验。 如果能够把大段的base64字符串放在文章末尾，然后在文章中通过一个id来调用，文章就不会被分割的这么乱了。就像写论文时的文末的注释和参考文档一样。这个想法可以通过markdown的参考式链接语法来实现。*进阶用法如下：文中引用语法：![avatar][doge]文末存储字符串语法：[doge]:data:image/png;base64,iVBORw0......这个用法不常见，比较野路子。优点是很灵活，不会有链接失效的困扰。缺点是一大团base64的乱码看着不美观。","categories":[{"name":"github","slug":"github","permalink":"https://www.sakuraus.cn/categories/github/"},{"name":"markdown","slug":"github/markdown","permalink":"https://www.sakuraus.cn/categories/github/markdown/"}],"tags":[{"name":"github","slug":"github","permalink":"https://www.sakuraus.cn/tags/github/"},{"name":"markdown","slug":"markdown","permalink":"https://www.sakuraus.cn/tags/markdown/"}]},{"title":"golang入门之捕捉panic","slug":"go_panic","date":"2018-09-01T16:00:00.000Z","updated":"2018-09-07T14:51:18.000Z","comments":true,"path":"2018/09/02/go_panic/","link":"","permalink":"https://www.sakuraus.cn/2018/09/02/go_panic/","excerpt":"","text":"在其他语言捕捉错误一般是用 try{}catch(E e){}1234567&lt;?phptry&#123; &#125;catch (Exception $e)&#123; // do something...&#125; 捕捉错误很有必要因为你可能不想因为一个小bug导致整个Application 崩溃 捕捉错误记录日志 能有效观察 正式环境的运行情况12345678910111213141516171819202122232425262728293031323334353637383940414243package mainimport ( \"encoding/json\" \"fmt\")type User struct &#123; UserName string `json:\"user_name\"` Age int&#125;func test() string &#123; user1 := &amp;User&#123; UserName: \"zheng\", Age: 22, &#125; defer func() &#123; if err := recover(); err != nil &#123; fmt.Println(err) &#125; &#125;() panic(\"error\") str, _ := json.Marshal(user1) return string(str)&#125;func main() &#123; var data string data = test() fmt.Println(data) var user1 map[string]interface&#123;&#125; err := json.Unmarshal([]byte(data), &amp;user1) if err != nil &#123; fmt.Println(err) return &#125; fmt.Println(\"user2 is\", user1)&#125; 这段代码我正在打包和解析 json 数据 我在 test()函数中手动panic 然后 defer在调用完当前函数后在执行 注意的是 defer必须写在 panic前面不然会报错 手动 panic 是不推荐的坐发可以用记录日志的方式的逻辑处理 panic 主要是语法写错了这类的基础错误 据说go 2.0版本会改进错误处理 golang fans 可以期待下(#^.^#) ,主要是支持泛型了 其他静态语言难找槽点了","categories":[{"name":"golang","slug":"golang","permalink":"https://www.sakuraus.cn/categories/golang/"}],"tags":[{"name":"golang","slug":"golang","permalink":"https://www.sakuraus.cn/tags/golang/"}]},{"title":"微服务架构理论-RPC通讯调用","slug":"微服务RPC","date":"2018-09-01T16:00:00.000Z","updated":"2018-09-02T03:59:19.000Z","comments":true,"path":"2018/09/02/微服务RPC/","link":"","permalink":"https://www.sakuraus.cn/2018/09/02/微服务RPC/","excerpt":"","text":"RPCwhat’s Rpc RPC（Remote Procedure Call）—远程过程调用，它是一种通过网络从远程计算机程序上请求服务，而不需要了解底层网络技术的协议。 比如说两台服务器A，B，一个应用部署在A服务器上，想要调用B服务器上应用提供的函数/方法，由于不在一个内存空间，不能直接调用，就需要通过网络来表达调用的语义和传达调用的数据，而这种方式就是rpc RPC 的主要功能目标是让构建分布式计算（应用）更容易，在提供强大的远程调用能力时不损失本地调用的语义简洁性。为实现该目标，RPC 框架需提供一种透明调用机制让使用者不必显式的区分本地调用和远程调用。 what need Rpc 分布式部署及微服务当我们的系统访问量增大、业务增多时，我们会发现一台单机运行此系统已经无法承受。此时，我们可以将业务拆分成几个互不关联的应用，分别部署在各自机器上，以划清逻辑并减小压力。 不同技术选型公司业务规模扩大，有可能引入不同的语言，比如A团队要开发CPU密集型的采用java语言，B团队要开发IO密集型的采用PHP，不同语言之间如何通讯 RPC call category 同步调用客户方等待调用执行完成并返回结果。 异步调用客户方调用后不用等待执行结果返回，但依然可以通过回调通知等方式获取返回结果。 若客户方不关心调用返回结果，则变成单向异步调用，单向调用不用返回结果。 异步和同步的区分在于是否等待服务端执行完成并返回结果。 如何调用他人的远程服务 由于各服务部署在不同机器，服务间的调用免不了网络通信过程，服务消费方每调用一个服务都要写一坨网络通信相关的代码，不仅复杂而且极易出错。 如果有一种方式能让我们像调用本地服务一样调用远程服务，而让调用者对网络通信这些细节透明，那么将大大提高生产力，比如服务消费方在执行$client-&gt;getUserInfo()时，实质上调用的是远端的服务。这种方式其实就是RPC（Remote Procedure Call Protocol），在各大互联网公司中被广泛使用，如阿里巴巴的hsf、dubbo（开源）、Facebook的thrift（开源）、Google grpc（开源）。 要让网络通信细节对使用者透明，我们自然需要对通信细节进行封装，我们先看下一个RPC调用的流程： rpc 服务消费方（client）调用以本地调用方式调用服务； client stub接收到调用后负责将方法、参数等组装成能够进行网络传输的消息体； client stub找到服务地址，并将消息发送到服务端； server stub收到消息后进行解码； server stub根据解码结果调用本地的服务； 本地服务执行并将结果返回给server stub； server stub将返回结果打包成消息并发送至消费方； client stub接收到消息，并进行解码； 服务消费方得到最终结果。","categories":[{"name":"MicroService","slug":"MicroService","permalink":"https://www.sakuraus.cn/categories/MicroService/"},{"name":"rpc","slug":"MicroService/rpc","permalink":"https://www.sakuraus.cn/categories/MicroService/rpc/"}],"tags":[{"name":"MicroService","slug":"MicroService","permalink":"https://www.sakuraus.cn/tags/MicroService/"},{"name":"rpc","slug":"rpc","permalink":"https://www.sakuraus.cn/tags/rpc/"}]},{"title":"微服务架构理论-基础与重要部件","slug":"微服务架构重要部件","date":"2018-09-01T16:00:00.000Z","updated":"2018-09-02T03:47:00.000Z","comments":true,"path":"2018/09/02/微服务架构重要部件/","link":"","permalink":"https://www.sakuraus.cn/2018/09/02/微服务架构重要部件/","excerpt":"","text":"内容介绍微服务基础客户端如何访问这些服务（api Gateway） 传统的开发方式，所有的服务都是本地的，UI可以直接调用，现在按功能拆分成独立的服务，跑在独立的运行环境中。客户端UI如何访问他的？后台有N个服务，前台就需要记住管理N个服务，一个服务下线/更新/升级，前台就要重新部署，这明显不服务我们拆分的理念，特别当前台是移动应用的时候，通常业务变化的节奏更快。另外，N个小服务的调用也是一个不小的网络开销。还有一般微服务在系统内部，通常是无状态的，用户登录信息和权限管理最好有一个统一的地方维护管理（OAuth）。 所以，一般在后台N个服务和UI之间一般会一个代理或者叫API Gateway，他的作用包括 •提供统一服务入口，让微服务对前台透明 •聚合后台的服务，节省流量，提升性能 •提供安全，过滤，流控等API管理功能 我的理解其实这个API Gateway可以有很多广义的实现办法，可以是一个软件比如kong，也可以是一个swoole的服务端自己编写的程序。他们最重要的作用是为前台（通常是移动应用）提供后台服务的聚合，提供一个统一的服务出口，解除他们之间的耦合，不过API Gateway也有可能成为单点故障点或者性能的瓶颈。 服务之间如何通信（服务调用） 因为所有的微服务都是独立的进程跑在独立的虚拟机上，所以服务间的通行就是IPC（inter process communication），已经有很多成熟的方案。现在基本最通用的有两种方式。这几种方式，展开来讲都可以写本书，而且大家一般都比较熟悉细节了， 就不展开讲了,简单了解下后面细讲 REST RPC 一般同步调用比较简单，一致性强，但是容易出调用问题，性能体验上也会差些，特别是调用层次多的时候。RESTful和RPC的比较也是一个很有意思的话题。一般REST基于HTTP，更容易实现，更容易被接受，服务端实现技术也更灵活些，各个语言都能支持，同时能跨客户端，对客户端没有特殊的要 求，只要封装了HTTP的SDK就能调用，所以相对使用的广一些。RPC也有自己的优点，传输协议更高效，安全更可控，特别在一个公司内部，如果有统一个的开发规范和统一的服务框架时，他的开发效率优势更明显些。就看各自的技术积累实际条件，自己的选择了。 这么多服务怎么查找（服务发现） 在微服务架构中，一般每一个服务都是有多个拷贝，来做负载均衡。一个服务随时可能下线，也可能应对临时访问压力增加新的服务节点。服务之间如何相互 感知？服务如何管理？这就是服务发现的问题了。一般有两类做法，也各有优缺点。基本都是通过consul等类似技术做服务注册信息的分布式管理。当 服务上线时，服务提供者将自己的服务信息注册到consul（或类似框架），并通过心跳检测健康状态，实时更新链接信息。服务调用者通过consul寻址，根据可定制算法，找到一个服务，还可以将服务信息缓存在本地以提高性能。当服务下线时，consul会发通知给服务客户端。 客户端做：优点是架构简单，扩展灵活，只对服务注册器依赖。缺点是客户端要维护所有调用服务的地址，有技术难度，一般大公司都有成熟的内部框架支持，比如Dubbo。 服务端做：所有服务对于前台调用方透明，一般在小公司在云服务上部署的应用采用的比较多。 service 服务挂了怎么办（服务熔断） 分布式最大的特性就是网络是不可靠 的。通过微服务拆分能降低这个风险，不过如果没有特别的保障，结局肯定是噩梦。比如一个线上故障就是一个很不起眼的数据库修改功能，在访问量上升 时，导致数据库load彪高，影响了所在应用的性能，从而影响所有调用这个应用服务的前台应用。所以当我们的系统是由一系列的服务调用链组成的时候，我们必须确保任一环节出问题都不至于影响整体链路。相应的手段有很多： 重试机制 限流 熔断机制 负载均衡 降级（本地缓存） 微服务重要组成服务注册中心 服务之间需要创建一种服务发现机制，用于帮助服务之间互相感知彼此的存在。服务启动时会将自身的服务信息注册到注册中心，并订阅自己需要消费的服务。 服务注册中心是服务发现的核心。它保存了各个可用服务实例的网络地址（IPAddress和Port）。服务注册中心必须要有高可用性和实时更新功能。上面提到的 consul 就是一个服务注册中心。它提供了服务注册和查询服务信息的REST API。服务通过使用POST请求注册自己的IPAddress和Port。每30秒发送一个PUT请求刷新注册信息。通过DELETE请求注销服务。客户端通过GET请求获取可用的服务实例信息。常见的服务注册中心的有： etcd —– 高可用，分布式，强一致性的，key-value，Kubernetes和Cloud Foundry都是使用了etcd。 consul —–一个用于discovering和configuring的工具。它提供了允许客户端注册和发现服务的API。Consul可以进行服务健康检查，以确定服务的可用性。 zookeeper —— 在分布式应用中被广泛使用，高性能的协调服务。 Apache Zookeeper 最初为Hadoop的一个子项目，但现在是一个顶级项目。 负载均衡 服务高可用的保证手段，为了保证高可用，每一个微服务都需要部署多个服务实例来提供服务。此时客户端进行服务的负载均衡 负载均衡的常见策略 随机把来自网络的请求随机分配给内部中的多个服务器。 轮询每一个来自网络中的请求，轮流分配给内部的服务器，从1到N然后重新开始。此种负载均衡算法适合服务器组内部的服务器都具有相同的配置并且平均服务请求相对均衡的情况。 加权轮询根据服务器的不同处理能力，给每个服务器分配不同的权值，使其能够接受相应权值数的服务请求。例如：服务器A的权值被设计成1，B的权值是3，C的权值是6，则服务器A、B、C将分别接受到10%、30％、60％的服务请求。此种均衡算法能确保高性能的服务器得到更多的使用率，避免低性能的服务器负载过重。 IP Hash这种方式通过生成请求源IP的哈希值，并通过这个哈希值来找到正确的真实服务器。这意味着对于同一主机来说他对应的服务器总是相同。使用这种方式，你不需要保存任何源IP。但是需要注意，这种方式可能导致服务器负载不平衡。 最少连接数客户端的每一次请求服务在服务器停留的时间可能会有较大的差异，随着工作时间加长，如果采用简单的轮循或随机均衡算法，每一台服务器上的连接进程可能会产生极大的不同，并没有达到真正的负载均衡。最少连接数均衡算法对内部中需负载的每一台服务器都有一个数据记录，记录当前该服务器正在处理的连接数量，当有新的服务连接请求时，将把当前请求分配给连接数最少的服务器，使均衡更加符合实际情况，负载更加均衡。此种均衡算法适合长时处理的请求服务，如FTP。 容错 容错，这个词的理解，直面意思就是可以容下错误，不让错误再次扩张，让这个错误产生的影响在一个固定的边界之内，“千里之堤毁于蚁穴”我们用容错的方式就是让这种蚁穴不要变大。那么我们常见的降级，限流，熔断器，超时重试等等都是容错的方法。 在调用服务集群时，如果一个微服务调用异常，如超时，连接异常，网络异常等，则根据容错策略进行服务容错。目前支持的服务容错策略有快速失败，失效切换。如果连续失败多次则直接熔断，不再发起调用。这样可以避免一个服务异常拖垮所有依赖于他的服务。 容错策略 快速失败服务只发起一次调用，失败立即报错。 失效切换服务发起调用，当出现失败后，重试其他服务器。通常用于读操作，但重试会带来更长时间的延迟。重试的次数通常是可以设置的 失败安全失败安全，当服务调用出现异常时，直接忽略。通常用于写入日志等操作。 失败自动恢复当服务调用出现异常时，记录失败请求，定时重发。通常用于消息通知。 广播调用广播调用所有提供者，逐个调用，任何一台失败则失败。通常用于通知所有提供者更新缓存或日志等本地资源信息 熔断 熔断技术可以说是一种“智能化的容错”，当调用满足失败次数，失败比例就会触发熔断器打开，有程序自动切断当前的RPC调用,来防止错误进一步扩大。实现一个熔断器主要是考虑三种模式，关闭，打开，半开。 breaker 我们在处理异常的时候，要根据具体的业务情况来决定处理方式，比如我们调用商品接口，对方只是临时做了降级处理，那么作为网关调用就要切到可替换的服务上来执行或者获取托底数据，给用户友好提示。还有要区分异常的类型，比如依赖的服务崩溃了，这个可能需要花费比较久的时间来解决。也可能是由于服务器负载临时过高导致超时。作为熔断器应该能够甄别这种异常类型，从而根据具体的错误类型调整熔断策略。增加手动设置，在失败的服务恢复时间不确定的情况下，管理员可以手动强制切换熔断状态。最后，熔断器的使用场景是调用可能失败的远程服务程序或者共享资源。如果是本地缓存本地私有资源，使用熔断器则会增加系统的额外开销。还要注意，熔断器不能作为应用程序中业务逻辑的异常处理替代品。 有一些异常比较顽固，突然发生，无法预测，而且很难恢复，并且还会导致级联失败（举个例子，假设一个服务集群的负载非常高，如果这时候集群的一部分挂掉了，还占了很大一部分资源，整个集群都有可能遭殃）。如果我们这时还是不断进行重试的话，结果大多都是失败的。因此，此时我们的应用需要立即进入失败状态(fast-fail)，并采取合适的方法进行恢复。 我们可以用状态机来实现CircuitBreaker，它有以下三种状态： 关闭( Closed )：默认情况下Circuit Breaker是关闭的，此时允许操作执行。CircuitBreaker内部记录着最近失败的次数，如果对应的操作执行失败，次数就会续一次。如果在某个时间段内，失败次数（或者失败比率）达到阈值，CircuitBreaker会转换到开启( Open )状态。在开启状态中，Circuit Breaker会启用一个超时计时器，设这个计时器的目的是给集群相应的时间来恢复故障。当计时器时间到的时候，CircuitBreaker会转换到半开启( Half-Open )状态。 开启( Open )：在此状态下，执行对应的操作将会立即失败并且立即抛出异常。 半开启( Half-Open )：在此状态下，Circuit Breaker会允许执行一定数量的操作。如果所有操作全部成功，CircuitBreaker就会假定故障已经恢复，它就会转换到关闭状态，并且重置失败次数。如果其中 任意一次 操作失败了，Circuit Breaker就会认为故障仍然存在，所以它会转换到开启状态并再次开启计时器（再给系统一些时间使其从失败中恢复） 限流和降级 保证核心服务的稳定性。为了保证核心服务的稳定性，随着访问量的不断增加，需要为系统能够处理的服务数量设置一个极限阀值，超过这个阀值的请求则直接拒绝。同时，为了保证核心服务的可用，可以对否些非核心服务进行降级，通过限制服务的最大访问量进行限流，通过管理控制台对单个微服务进行人工降级 关于降级限流的方法业界都已经有很成熟的方法了，比如FAILBACK机制，限流的方法令牌桶，漏桶，信号量等。这里谈一下我们的一些经验，降级一般都是由统一配置中心的降级开关来实现的，那么当有很多个接口来自同一个提供方，这个提供方的系统或这机器所在机房网络出现了问题，我们就要有一个统一的降级开关，不然就要一个接口一个接口的来降级。也就是要对业务类型有一个大闸刀。还有就是 降级切记暴力降级，什么是暴力降级的，比如把论坛功能降调，结果用户显示一个大白板，我们要实现缓存住一些数据，也就是有托底数据。限流一般分为分布式限流和单机限流，如果实现分布式限流的话就要一个公共的后端存储服务比如redis，在大nginx节点上利用lua读取redis配置信息 API网关 这里说的网关是指API网关，直面意思是将所有API调用统一接入到API网关层，有网关层统一接入和输出。一个网关的基本功能有：统一接入、安全防护、协议适配、流量管控、长短链接支持、容错能力。有了网关之后，各个API服务提供团队可以专注于自己的的业务逻辑处理，而API网关更专注于安全、流量、路由等问题。 超时和重试 超时与重试机制也是容错的一种方法，凡是发生RPC调用的地方，比如读取redis，db，mq等，因为网络故障或者是所依赖的服务故障，长时间不能返回结果，就会导致线程增加，加大cpu负载，甚至导致雪崩。所以对每一个RPC调用都要设置超时时间。 对于强依赖RPC调用资源的情况，还要有重试机制，但是重试的次数建议1-2次，另外如果有重试，那么超时时间就要相应的调小，比如重试1次，那么一共是发生2次调用。如果超时时间配置的是2s，那么客户端就要等待4s才能返回。因此重试+超时的方式，超时时间要调小。 这里也再谈一下一次PRC调用的时间都消耗在哪些环节，一次正常的调用统计的耗时主要包括： ①调用端RPC框架执行时间 + ②网络发送时间 + ③服务端RPC框架执行时间 + ④服务端业务代码时间。调用方和服务方都有各自的性能监控，比如调用方tp99是500ms，服务方tp99是100ms，找了网络组的同事确认网络没有问题。那么时间都花在什么地方了呢，两种原因，客户端调用方，还有一个原因是网络发生TCP重传。所以要注意这两点。","categories":[{"name":"MicroService","slug":"MicroService","permalink":"https://www.sakuraus.cn/categories/MicroService/"}],"tags":[{"name":"MicroService","slug":"MicroService","permalink":"https://www.sakuraus.cn/tags/MicroService/"}]},{"title":"微服务架构—微服务介绍","slug":"微服务详解","date":"2018-09-01T16:00:00.000Z","updated":"2018-09-02T03:11:08.000Z","comments":true,"path":"2018/09/02/微服务详解/","link":"","permalink":"https://www.sakuraus.cn/2018/09/02/微服务详解/","excerpt":"","text":"什么是微服务 在介绍微服务时，首先得先理解什么是微服务，顾名思义，微服务得从两个方面去理解，什么是”微”、什么是”服务”， 微 狭义来讲就是体积小、著名的”2 pizza 团队”很好的诠释了这一解释（2 pizza 团队最早是亚马逊 CEO Bezos提出来的，意思是说单个服务的设计，所有参与人从设计、开发、测试、运维所有人加起来 只需要2个披萨就够了 ）。 而所谓服务，一定要区别于系统，服务一个或者一组相对较小且独立的功能单元，是用户可以感知最小功能集。 微服务的由来 微服务最早由Martin Fowler与James Lewis于2014年共同提出，微服务架构风格是一种使用一套小服务来开发单个应用的方式途径，每个服务运行在自己的进程中，并使用轻量级机制通信，通常是HTTP API，这些服务基于业务能力构建，并能够通过自动化部署机制来独立部署，这些服务使用不同的编程语言实现，以及不同数据存储技术，并保持最低限度的集中式管理。 为什么需要微服务？ 在传统的IT行业软件大多都是各种独立系统的堆砌，这些系统的问题总结来说就是扩展性差，可靠性不高，维护成本高。到后面引入了.服务化，但是，由于 SOA 早期均使用了总线模式，这种总线模式是与某种技术栈强绑定的，这导致很多企业的遗留系统很难对接，切换时间太长，成本太高，新系统稳定性的收敛也需要一些时间。最终 SOA 看起来很美，但却成为了企业级奢侈品，中小公司都望而生畏 什么样的项目适合微服务 单体架构在规模比较小的情况下工作情况良好，但是随着系统规模的扩大，它暴露出来的问题也越来越多，主要有以下几点： 复杂性逐渐变高 比如有的项目有几十万行代码，各个模块之间区别比较模糊，逻辑比较混乱，代码越多复杂性越高，越难解决遇到的问题。 技术债务逐渐上升 公司的人员流动是再正常不过的事情，有的员工在离职之前，疏于代码质量的自我管束，导致留下来很多坑，由于单体项目代码量庞大的惊人，留下的坑很难被发觉，这就给新来的员工带来很大的烦恼，人员流动越大所留下的坑越多，也就是所谓的技术债务越来越多。 阻碍技术创新 比如以前的某个项目使用tp3.2写的，由于各个模块之间有着千丝万缕的联系，代码量大，逻辑不够清楚，如果现在想用tp5来重构这个项目将是非常困难的，付出的成本将非常大，所以更多的时候公司不得不硬着头皮继续使用老的单体架构，这就阻碍了技术的创新。 无法按需伸缩 比如说电影模块是CPU密集型的模块，而订单模块是IO密集型的模块，假如我们要提升订单模块的性能，比如加大内存、增加硬盘，但是由于所有的模块都在一个架构下，因此我们在扩展订单模块的性能时不得不考虑其它模块的因素，因为我们不能因为扩展某个模块的性能而损害其它模块的性能，从而无法按需进行伸缩。 微服务拆分与设计微服务与单体架构区别 单体架构所有的模块全都耦合在一块，代码量大，维护困难，微服务每个模块就相当于一个单独的项目，代码量明显减少，遇到问题也相对来说比较好解决。 单体架构所有的模块都共用一个数据库，存储方式比较单一，微服务每个模块都可以使用不同的存储方式（比如有的用redis，有的用mysql等），数据库也是单个模块对应自己的数据库。 单体架构所有的模块开发所使用的技术一样，微服务每个模块都可以使用不同的开发技术，开发模式更灵活。 微服务与SOA区别 微服务，从本质意义上看，还是 SOA 架构。但内涵有所不同，微服务并不绑定某种特殊的技术，在一个微服务的系统中，可以有 Java 编写的服务，也可以有 php编写的服务，他们是靠Restful架构风格统一成一个系统的。所以微服务本身与具体技术实现无关，扩展性强。 相比传统SOA的服务实现方式，微服务更具有灵活性、可实施性以及可扩展性，其强调的是一种独立测试、独立部署、独立运行的软件架构模式。 微服务拆分与设计 从单体式结构转向微服务架构中会持续碰到服务边界划分的问题：比如，我们有user 服务来提供用户的基础信息，那么用户的头像和图片等是应该单独划分为一个新的service更好还是应该合并到user服务里呢？如果服务的粒度划分的过粗，那就回到了单体式的老路；如果过细，那服务间调用的开销就变得不可忽视了，管理难度也会指数级增加。目前为止还没有一个可以称之为服务边界划分的标准，只能根据不同的业务系统加以调节 拆分的大原则是当一块业务不依赖或极少依赖其它服务，有独立的业务语义，为超过2个的其他服务或客户端提供数据，那么它就应该被拆分成一个独立的服务模块。 微服务设计原则 单一职责原则意思是每个微服务只需要实现自己的业务逻辑就可以了，比如订单管理模块，它只需要处理订单的业务逻辑就可以了，其它的不必考虑。 服务自治原则意思是每个微服务从开发、测试、运维等都是独立的，包括存储的数据库也都是独立的，自己就有一套完整的流程，我们完全可以把它当成一个项目来对待。不必依赖于其它模块。 轻量级通信原则首先是通信的语言非常的轻量，第二，该通信方式需要是跨语言、跨平台的，之所以要跨平台、跨语言就是为了让每个微服务都有足够的独立性，可以不受技术的钳制。 接口明确原则由于微服务之间可能存在着调用关系，为了尽量避免以后由于某个微服务的接口变化而导致其它微服务都做调整，在设计之初就要考虑到所有情况，让接口尽量做的更通用，更灵活，从而尽量避免其它模块也做调整。 微服务优势与缺点特性 每个微服务可独立运行在自己的进程里； 一系列独立运行的微服务共同构建起了整个系统； 每个服务为独立的业务开发，一个微服务一般完成某个特定的功能，比如：订单管理，用户管理等； 微服务之间通过一些轻量级的通信机制进行通信，例如通过REST API或者RPC的方式进行调用。 优点 易于开发和维护由于微服务单个模块就相当于一个项目，开发这个模块我们就只需关心这个模块的逻辑即可，代码量和逻辑复杂度都会降低，从而易于开发和维护。 启动较快这是相对单个微服务来讲的，相比于启动单体架构的整个项目，启动某个模块的服务速度明显是要快很多的。 局部修改容易部署在开发中发现了一个问题，如果是单体架构的话，我们就需要重新发布并启动整个项目，非常耗时间，但是微服务则不同，哪个模块出现了bug我们只需要解决那个模块的bug就可以了，解决完bug之后，我们只需要重启这个模块的服务即可，部署相对简单，不必重启整个项目从而大大节约时间。 技术栈不受限比如订单微服务和电影微服务原来都是用java写的，现在我们想把电影微服务改成php技术，这是完全可以的，而且由于所关注的只是电影的逻辑而已，因此技术更换的成本也就会少很多。 按需伸缩我们上面说了单体架构在想扩展某个模块的性能时不得不考虑到其它模块的性能会不会受影响，对于我们微服务来讲，完全不是问题，电影模块通过什么方式来提升性能不必考虑其它模块的情况。 缺点 运维要求较高对于单体架构来讲，我们只需要维护好这一个项目就可以了，但是对于微服务架构来讲，由于项目是由多个微服务构成的，每个模块出现问题都会造成整个项目运行出现异常，想要知道是哪个模块造成的问题往往是不容易的，因为我们无法一步一步通过debug的方式来跟踪，这就对运维人员提出了很高的要求。 分布式的复杂性对于单体架构来讲，我们可以不使用分布式，但是对于微服务架构来说，分布式几乎是必会用的技术，由于分布式本身的复杂性，导致微服务架构也变得复杂起来。 接口调整成本高比如，用户微服务是要被订单微服务和电影微服务所调用的，一旦用户微服务的接口发生大的变动，那么所有依赖它的微服务都要做相应的调整，由于微服务可能非常多，那么调整接口所造成的成本将会明显提高。 重复劳动对于单体架构来讲，如果某段业务被多个模块所共同使用，我们便可以抽象成一个工具类，被所有模块直接调用，但是微服务却无法这样做，因为这个微服务的工具类是不能被其它微服务所直接调用的，从而我们便不得不在每个微服务上都建这么一个工具类，从而导致代码的重复。","categories":[{"name":"MicroService","slug":"MicroService","permalink":"https://www.sakuraus.cn/categories/MicroService/"}],"tags":[{"name":"MicroService","slug":"MicroService","permalink":"https://www.sakuraus.cn/tags/MicroService/"}]},{"title":"实战微服务之 live直播服务","slug":"swoft","date":"2018-09-01T16:00:00.000Z","updated":"2018-09-02T03:59:57.000Z","comments":true,"path":"2018/09/02/swoft/","link":"","permalink":"https://www.sakuraus.cn/2018/09/02/swoft/","excerpt":"","text":"Live直播说明 本次实战使用php swoft实现整个推流到视频转码到客户端关观看 业务图解live edge-srsdockerdocker-composeconsulconsul-templateSwoft 文档 WebSocket","categories":[{"name":"live","slug":"live","permalink":"https://www.sakuraus.cn/categories/live/"},{"name":"MicroService","slug":"live/MicroService","permalink":"https://www.sakuraus.cn/categories/live/MicroService/"}],"tags":[{"name":"docker","slug":"docker","permalink":"https://www.sakuraus.cn/tags/docker/"},{"name":"docker-compose","slug":"docker-compose","permalink":"https://www.sakuraus.cn/tags/docker-compose/"},{"name":"MicroService","slug":"MicroService","permalink":"https://www.sakuraus.cn/tags/MicroService/"},{"name":"srs","slug":"srs","permalink":"https://www.sakuraus.cn/tags/srs/"},{"name":"swoft","slug":"swoft","permalink":"https://www.sakuraus.cn/tags/swoft/"},{"name":"service","slug":"service","permalink":"https://www.sakuraus.cn/tags/service/"},{"name":"consul","slug":"consul","permalink":"https://www.sakuraus.cn/tags/consul/"},{"name":"swoole","slug":"swoole","permalink":"https://www.sakuraus.cn/tags/swoole/"}]},{"title":"访问Pixiv新host","slug":"pixiv-host","date":"2018-09-01T16:00:00.000Z","updated":"2018-09-02T04:10:40.000Z","comments":true,"path":"2018/09/02/pixiv-host/","link":"","permalink":"https://www.sakuraus.cn/2018/09/02/pixiv-host/","excerpt":"","text":"(:з」∠)接好 angel 210.129.120.46 pixiv.net 210.129.120.46 www.pixiv.net 210.129.120.46 accounts.pixiv.net 210.129.120.46 touch.pixiv.net 210.140.131.153 source.pixiv.net 210.140.131.153 imgaz.pixiv.net 210.129.120.46 app-api.pixiv.net 210.129.120.46 oauth.secure.pixiv.net 210.129.120.46 dic.pixiv.net 210.140.131.144 comic.pixiv.net 210.140.131.184 factory.pixiv.net 74.120.148.201 g-client-proxy.pixiv.net 210.140.170.179 sketch.pixiv.net 210.129.120.46 payment.pixiv.net 210.129.120.46 sensei.pixiv.net 210.129.120.46 bungei.pixiv.net 210.140.131.147 novel.pixiv.net 210.129.120.46 en.dic.pixiv.net 210.140.131.160 d.pixiv.org 210.140.131.147 imgsi1.pixiv.net 210.140.131.147 imgsi2.pixiv.net 210.140.131.153 comic.pixiv.net 210.140.131.153 source.pixiv.net 122.208.114.218 p2.pixiv.net 210.129.120.46 embed.pixiv.net 210.129.120.60 ns1.pixiv.net 210.129.120.62 ns2.pixiv.net 210.140.131.180 factory.pixiv.net 210.129.120.46 mylovestreet.pr.pixiv.net 210.129.120.46 ssl.pixiv.net 210.129.120.46 recruit.pixiv.net 52.85.158.157 matsuri.pixiv.net 54.182.2.30 matsuri.pixiv.net 210.129.120.46 m.pixiv.net 52.222.234.251 iracon.pixiv.net 210.129.120.50 inside.pixiv.net 153.120.23.207 help.pixiv.net 210.129.120.46 goods.pixiv.net 52.222.234.232 festa.pixiv.net 52.219.68.156 dev.pixiv.net 210.129.120.46 chat.pixiv.net 122.208.114.218 blog.pixiv.net 210.129.120.46 comic-api.pixiv.net 210.129.120.46 fanbox.pixiv.net 210.129.120.46 pool.pr.pixiv.net 210.129.120.46 hug.pr.pixiv.net 210.129.120.46 pixiv-essay.pr.pixiv.net 210.129.120.46 cheek.pr.pixiv.net 210.129.120.46 kurofune.pr.pixiv.net 210.129.120.46 gangan.pr.pixiv.net 210.129.120.46 mint.pr.pixiv.net 151.101.165.195 chatstory.pixiv.net 52.84.49.43 market.pixiv.net 210.129.120.46 en-dic.pixiv.net 210.140.131.182 vroid.pixiv.net 167.89.118.52 link.pixiv.net","categories":[{"name":"pixiv","slug":"pixiv","permalink":"https://www.sakuraus.cn/categories/pixiv/"},{"name":"插画","slug":"pixiv/插画","permalink":"https://www.sakuraus.cn/categories/pixiv/插画/"}],"tags":[{"name":"pixiv","slug":"pixiv","permalink":"https://www.sakuraus.cn/tags/pixiv/"},{"name":"插画","slug":"插画","permalink":"https://www.sakuraus.cn/tags/插画/"}]},{"title":"初探srs流媒体-edge边缘服务器","slug":"srs-edge","date":"2018-08-30T16:00:00.000Z","updated":"2018-09-02T14:03:43.000Z","comments":true,"path":"2018/08/31/srs-edge/","link":"","permalink":"https://www.sakuraus.cn/2018/08/31/srs-edge/","excerpt":"","text":"SRS 边缘(edge) 所谓边缘edge服务器，就是边缘直播缓存服务器，配置时指定为remote模式和origin*（指定一个或多个源站IP），这个边缘edge服务器就是源站的缓存了 当用户播放边缘服务器的流时，边缘服务器看有没有缓存，若缓存了就直接将流发给客户端。若没有缓存，则发起一路回源链接，从源站取数据源源不断放到自己的缓存队列。也就是说， 多个客户端连接到边缘时，只有一路回源。这种结构在CDN是最典型的部署结构。譬如北京源站， 在全国32个省每个省都部署了10台服务器，一共就有320台边缘，假设每个省1台边缘服务器都有 2000用户观看，那么就有64万用户，每秒钟集群发送640Gbps数据；而回源链接只有320个， 实现了大规模分发。 边缘edge服务器，实际上是解决大并发问题产生的分布式集群结构。SRS的边缘可以指定多个源站， 在源站出现故障时会自动切换到下一个源站，不影响用户观看，具有最佳的容错性，用户完全不会觉察。 总结:使用edge的好处可以承受更大并发也很容易就能搭建一个srs集群 提高了srs容错.即使srs出了问题在切换源的途中用户也不会察觉 工作模式: 假如我现在有 47.104.10.92:9524 , 127.0.0.1:5685 两台rtmp集群 用户推流只能向一台srs服务器推流如果用户A 在 47.104.10.92:9524 rmtp推流成功,那其他用户也只能通过 47.104.10.92:9524 获取视频流如果使用上 edge 不管 视频流在 47.104.10.92:9524,127.0.0.1:5685 那台srs服务器上edge 会遍历 srs服务器 查询到源站视频流的节点然后建立连接,这样就做了一个很好的中转 文档 edge 注意：优先使用edge，除非知道必须用forward，才使用forward。(forward热备:就是拷贝流到其他srs并不能实现主从)","categories":[{"name":"srs","slug":"srs","permalink":"https://www.sakuraus.cn/categories/srs/"}],"tags":[{"name":"srs","slug":"srs","permalink":"https://www.sakuraus.cn/tags/srs/"}]}]}